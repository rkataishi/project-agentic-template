# TOFA-WDF DOCUMENTATION CONSOLIDATED

Este documento fue generado automÃ¡ticamente con todos los archivos relevantes del ciclo TOFA-WDF.

## Ãrbol de directorios incluidos

```
# .
.
â”œâ”€â”€ .all_tofa.md
â”œâ”€â”€ adr
â”œâ”€â”€ external_knowledge
â”‚Â Â  â”œâ”€â”€ know_docs_task-master.md
â”‚Â Â  â””â”€â”€ know_task_master_integration.md
â”œâ”€â”€ integrate_tofa_docs.py
â”œâ”€â”€ onboarding
â”œâ”€â”€ onboarding.md
â”œâ”€â”€ pipeline
â”‚Â Â  â”œâ”€â”€ active -> tags/master/
â”‚Â Â  â””â”€â”€ tags
â”‚Â Â      â””â”€â”€ master
â”‚Â Â          â”œâ”€â”€ master -> tags/master/
â”‚Â Â          â”œâ”€â”€ pipeline_development.md
â”‚Â Â          â””â”€â”€ pipeline_pickup.md
â”œâ”€â”€ rules
â”‚Â Â  â”œâ”€â”€ rule_code_quality.md
â”‚Â Â  â”œâ”€â”€ rule_code_review_manual.md
â”‚Â Â  â”œâ”€â”€ rule_cross_task_coordination.md
â”‚Â Â  â”œâ”€â”€ rule_dependency_management.md
â”‚Â Â  â”œâ”€â”€ rule_doc_guidelines.md
â”‚Â Â  â”œâ”€â”€ rule_knowledge_management.md
â”‚Â Â  â”œâ”€â”€ rule_knowledge_sync_policy.md
â”‚Â Â  â”œâ”€â”€ rule_security_guidelines.md
â”‚Â Â  â”œâ”€â”€ rule_self_improve.md
â”‚Â Â  â”œâ”€â”€ rule_test_data_policy.md
â”‚Â Â  â””â”€â”€ rule_vscode_rules.md
â””â”€â”€ templates
    â”œâ”€â”€ config
    â”‚Â Â  â””â”€â”€ template_config.py
    â”œâ”€â”€ template_adr.md
    â”œâ”€â”€ template_learning_by_doing.md
    â”œâ”€â”€ template_memories.md
    â””â”€â”€ template_task_contract.md

11 directories, 24 files
# ../.github/instructions
../.github/instructions
â”œâ”€â”€ dev_workflow.md
â””â”€â”€ taskmaster.md

1 directory, 2 files
# ../.taskmaster
../.taskmaster
â”œâ”€â”€ config.json
â”œâ”€â”€ state.json
â””â”€â”€ templates
    â””â”€â”€ example_prd.txt

2 directories, 3 files
```

## DocumentaciÃ³n consolidada


========================================================================================================================

## FILE: `integrate_tofa_docs.py`

```markdown
# compile_all_tofa_docs.py

import os
import subprocess

# Rutas especÃ­ficas a incluir, relativas a docs/
doc_root = "."
external_dirs = [
    "../.github/instructions",
    "../.taskmaster"
]

all_dirs = [doc_root] + external_dirs
output_file = ".all_tofa.md"
output_lines = []

# Encabezado general
output_lines.append("# TOFA-WDF DOCUMENTATION CONSOLIDATED\n")
output_lines.append("Este documento fue generado automÃ¡ticamente con todos los archivos relevantes del ciclo TOFA-WDF.\n")

# Ãrbol manual limitado a las carpetas relevantes
output_lines.append("## Ãrbol de directorios incluidos\n")
output_lines.append("```")
for path in all_dirs:
    output_lines.append(f"# {os.path.normpath(path)}")
    try:
        tree_output = subprocess.check_output(["tree", "-a", "-I", "__pycache__|.DS_Store|*.pyc", "-L", "5", path], encoding="utf-8")
        output_lines.append(tree_output.strip())
    except Exception as e:
        output_lines.append(f"[ERROR] No se pudo generar tree para {path}: {e}")
output_lines.append("```\n")

# CompilaciÃ³n de documentos
output_lines.append("## DocumentaciÃ³n consolidada\n")

for base_dir in all_dirs:
    for root, _, files in os.walk(base_dir):
        for file in sorted(files):
            if file.startswith(".") or file.endswith(".DS_Store"):
                continue
            file_path = os.path.join(root, file)
            rel_path = os.path.relpath(file_path, start=doc_root)
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                output_lines.append("\n" + "=" * 120)
                output_lines.append(f"\n## FILE: `{rel_path}`\n")
                output_lines.append("```markdown")
                output_lines.append(content.strip())
                output_lines.append("```")
            except Exception as e:
                output_lines.append("\n" + "=" * 120)
                output_lines.append(f"\n## ERROR: Could not read {rel_path} - {str(e)}\n")

# Escritura final
with open(output_file, "w", encoding="utf-8") as f:
    f.write("\n".join(output_lines))
```

========================================================================================================================

## FILE: `onboarding.md`

```markdown
# Project Onboarding: Your Starting Point

Welcome to the project. This document is your guide to getting set up, understanding our workflow, and contributing effectively. **Read this entire document before writing any code.**

Its purpose is to be your onboarding lead, your initial set of instructions, and a central hub that links to all other critical documentation. Following these steps will allow you to start working autonomously and correctly.

**Assumption:** The initial Product Requirements Document (`prd.md`) has been created and is located at `docs/pipeline/active/prd.md`.

---

## Step 1: Initial Environment Setup

These commands will prepare your local environment.

1.  **Clone the Repository:**
    ```bash
    git clone <your-repository-url>
    cd <repository-name>
    ```

2.  **Create the Project Structure (if not already present):**
    ```bash
    # This script creates all the necessary directories and template files.
    chmod +x setup_pipeline.sh
    ./setup_pipeline.sh
    ```

3.  **Set up the Python Environment (using Poetry):**
    *Our project uses [Poetry](https://python-poetry.org/) for dependency management. See `docs/rules/rule_dependency_management.md` for details.*
    ```bash
    # This command reads pyproject.toml, creates a virtual environment, and installs all dependencies.
    poetry install
    ```

4.  **Configure Local Secrets:**
    *This is a critical security step. We never commit secrets to the repository.*
    ```bash
    # 1. Copy the template to create your local, untracked config file.
    cp docs/templates/config/template_config.py config/config.py

    # 2. Create a .env file for your secrets. This file is in .gitignore.
    touch .env
    ```
    **Action:** Open the `.env` file and add your secret keys (e.g., `OPENAI_API_KEY="sk-..."`). The `config/config.py` file will load these automatically.

5.  **Verify Your Setup:**
    *Run the project's test suite to ensure everything is installed and configured correctly.*
    ```bash
    poetry run pytest
    ```
    If all tests pass, your environment is ready.

---

## Step 2: Understand the Mission and Workflow

Your next step is to absorb the project's context.

-   **The "Why" (The Mission):**
    -   **Action:** Read the Product Requirements Document (PRD).
    -   **Location:** `docs/pipeline/active/prd.md`

-   **The "How" (The Development Process):**
    -   **Action:** This is a **mandatory reading**. It defines our entire development lifecycle.
    -   **Location:** `docs/pipeline/pipeline_development.md`

-   **Resuming Work:**
    -   **Action:** Familiarize yourself with the checklist for picking up work after a break.
    -   **Location:** `docs/pipeline/pipeline_pickup.md`

---

## Step 3: Understand the Rules and Principles

This project is governed by a set of rules to ensure quality, consistency, and security. It is your responsibility to know and follow them.

-   **The Rulebook:**
    -   **Action:** Review the contents of the `docs/rules/` directory. All files within are mandatory.
    -   **Key Rules to Internalize:**
        -   `rule_code_quality.md`: How we write and format code (Black, Ruff).
        -   `rule_doc_guidelines.md`: Naming conventions and documentation standards.
        -   `rule_security_guidelines.md`: Our policies on handling secrets and data.
        -   `rule_knowledge_management.md`: How we document decisions using ADRs.

-   **Core Behavioral Principles:**
    1.  **Documentation First:** Changes to standards or architecture are documented *before* they are coded.
    2.  **Traceability is Non-Negotiable:** Every piece of logic must be traceable back to a plan in `microtasks.md`.
    3.  **No Silent Failures:** Code must fail loudly and explicitly. Errors are valuable data.
    4.  **Automate Quality:** Rely on linters and formatters, not manual perfection.
    5.  **Commit Defensively:** Write clear commit messages. Ensure your code is linted and tested before you push.

---

## Step 4: Your First Task

You are now ready to begin.

1.  **Find Your Next Task:**
    ```bash
    # Use the Task Master CLI to see the task list or get a recommendation.
    task-master list
    task-master next
    ```

2.  **Review the Active Plan:**
    -   **Action:** Read the current plan for your assigned task.
    -   **Location:** `docs/pipeline/active/microtasks.md`

3.  **Begin the Development Cycle:**
    -   **Action:** Follow the process outlined in `docs/pipeline/pipeline_development.md`.

---

## Quick Reference Links

- **Project Root:** `docs/pipeline/active/`
- **Rules:** `docs/rules/`
- **Templates:** `docs/templates/`
- **ADRs:** `docs/adr/`
- **Configuration:** `config/`

---

**Welcome aboard! If you have questions, check the documentation first, then ask in the project chat.**
```

========================================================================================================================

## ERROR: Could not read pipeline/tags/master/master - [Errno 2] No such file or directory: './pipeline/tags/master/master'


========================================================================================================================

## FILE: `pipeline/tags/master/pipeline_development.md`

```markdown
# TOFA-WDF + Task Master â€“ Iterative Development Pipeline (v4.0)

This pipeline governs the complete lifecycle of a technical task using **TOFA-WDF**, integrated with **Task Master** for planning and enhanced with real-time memory management for continuity and traceability.

> ğŸ”§ **Directory Structure Guidelines:**
> - `docs/` is the single source of truth for all project documentation, including workflow guides, rules, templates, and external knowledge.
> - For TaskMaster documentation, see `docs/external_knowledge/know_docs_task-master.md`.
> - For TaskMaster integration details, see `docs/external_knowledge/know_task_master_integration.md`.

---

## Architecture Overview

### The Four-Tier Architecture

Think of TOFA-WDF as a **factory assembly line**:

1.  **Modules** (`simple/`) â†’ **Atomic workers** doing one specific job (inside a capability's `functions/` directory).
2.  **Orchestrators** (`orchestrators/`) â†’ **Team leaders** coordinating workers (inside a capability's `functions/` directory).
3.  **Flows** (`flows/`) â†’ **Factory managers** coordinating multiple teams (at the project root).
4.  **Scripts** (`scripts/`) â†’ **Control room** receiving external commands (inside a capability's directory).

### Project Structure

```plaintext
project/
â”œâ”€â”€ data_processing/            # Capability-specific folder
â”‚   â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ functions/
â”‚   â”‚   â”œâ”€â”€ simple/
â”‚   â”‚   â””â”€â”€ orchestrators/
â”‚   â””â”€â”€ test_data/
â”œâ”€â”€ reporting/                  # Another capability folder
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ tasks/                      # For Task Master's generated .md files ONLY
â”‚
â”œâ”€â”€ docs/                       # ALL project documentation
â”‚   â”œâ”€â”€ external_knowledge/
â”‚   â”‚   â”œâ”€â”€ know_docs_task-master.md
â”‚   â”‚   â””â”€â”€ know_task_master_integration.md
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ active -> tags/master/        # Symlink to the active context
â”‚   â”‚   â”œâ”€â”€ pipeline_development.md       # This guide
â”‚   â”‚   â”œâ”€â”€ pipeline_pickup.md            # How to resume work
â”‚   â”‚   â””â”€â”€ tags/
â”‚   â”‚       â””â”€â”€ master/
â”‚   â”‚           â”œâ”€â”€ prd.md
â”‚   â”‚           â””â”€â”€ ... (other active context files)
â”‚   â”œâ”€â”€ rules/
â”‚   â”‚   â”œâ”€â”€ rule_code_review_manual.md
â”‚   â”‚   â”œâ”€â”€ rule_cross_task_coordination.md
â”‚   â”‚   â”œâ”€â”€ rule_doc_guidelines.md
â”‚   â”‚   â””â”€â”€ ... (all other project rules)
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â””â”€â”€ template_config.py      # <-- MUST be copied to /config/config.py
â”‚       â”œâ”€â”€ template_learning_by_doing.md
â”‚       â”œâ”€â”€ template_memories.md
â”‚       â””â”€â”€ template_task_contract.md
â”‚
â”œâ”€â”€ flows/                      # Cross-capability orchestration
â”œâ”€â”€ shared_modules/             # Reusable utilities
â””â”€â”€ config/                     # Project-specific configuration (populated from template)
    â””â”€â”€ config.py               # <-- This file is created from the template
```

---

### **Phase 1: AI-Led Scoping and Backlog Creation**

The project begins with an AI-powered scoping phase to generate a comprehensive task backlog.

1.  **Author the PRD:** Create or update the `prd.md` file within the active pipeline context (e.g., `docs/pipeline/active/prd.md`). This document outlines the high-level goals and requirements.
2.  **Generate the Task Backlog:** Run the native Taskmaster command to parse the PRD.
    *   **Command:** `task-master parse-prd docs/pipeline/active/prd.md`
    *   **Result:** Taskmaster creates the initial `tasks.json` file, populating it with a full list of tasks derived from the PRD. This is the project's **master backlog**.

---

### **Phase 2: Human-Approved Strategic Planning**

Before any code is written, a human developer must create a focused, strategic plan for the immediate work session.

1.  **Select the Next Task:** Review the master backlog using `task-master list` and identify the next task to be implemented. Use `task-master next` for a recommendation.
2.  **Define the Microtask Plan:** Open the `microtasks.md` file in the active context (e.g., `docs/pipeline/active/microtasks.md`). In this file, write a detailed, human-authored plan for implementing the single task selected in the previous step.
    *   **This document is the **single source of truth** for the AI agent's immediate coding session.** It provides the "what" and the "why."

---

### **Phase 3: AI-Assisted Implementation and Tactical Logging**

The AI agent executes the plan from `microtasks.md` and logs its progress in a separate, tactical log.

1.  **Implementation:** The agent writes code based on the plan in `microtasks.md`.
2.  **Tactical Logging:** As the agent works, it **must** log its findings, successes, and failures using the `update-subtask` command. This creates a timestamped, granular implementation history within `tasks.json`.
    *   **Example Command:** `task-master update-subtask --id=5.2 --prompt="[LOG] Successfully connected to the database. The connection string required ssl=true. This was not in the initial plan."`
    *   This log provides the "how."
3.  **Synthesize Knowledge:** Upon task completion, the strategic insights from the tactical log are synthesized and recorded in `docs/pipeline/active/memories.md`.

---

### **Phase 4: Iterative Implementation Loop**

#### **A. Module Development**
- Develop **Modules** (pure, atomic functions) in `<capability_name>/functions/simple/` (e.g., `data_processing/functions/simple/`).
- Each logical step is a **Microtask**.
- Immediately write and validate a unit test for each Module.
- **Principle**: No function exists without a test. Governed by `docs/rules/rule_test_data_policy.md`.
- Functions must be stateless: all logic must depend only on explicitly passed arguments.
- Return values must contain all necessary outputs for the next processing step.

#### **B. Composition**
- Compose **Modules** into **Orchestrators** in `<capability_name>/functions/orchestrators/`.
- Compose **Orchestrators** into **Flows** in the root `flows/` directory.
- Keep orchestrators focused on coordination, not atomic logic.
- Orchestrators must manage the data flow explicitly between modules via argument passing.
- Avoid using intermediate storage or global variables to transfer state between steps. See `docs/rules/rule_cross_task_coordination.md`.

#### **C. Script Construction and Testing**
- Write **Scripts** in `<capability_name>/scripts/` that run orchestrators or flows.
- Run on real, sampled data with logging.
- Use a structured logger for all outputs.
- Ensure that logs are saved to the root `logs/` directory and include task name and timestamp.
- Avoid inline `print()` for traceabilityâ€”use logger methods like `.info()`, `.error()`, `.warning()` instead.
- Mark progress using the native Taskmaster command: `task-master set-status --id <id> --status in-progress`.
- **Every issue triggers**:
  - Documentation in `docs/pipeline/active/microtasks.md`.
  - A new task if significant: `task-master add-task --prompt "Investigate..."`.

#### **D. LLM-Assisted Revision**
- Use an LLM agent for refactors, alternatives, or diagnostics.
- **Certainty principle**: <80% certainty, ask; 80-95% certainty, offer options; >95% certainty, act.
- Update all relevant files if the scope changes.

#### **E. Re-Execution and Retest**
- Run again with updated code.
- Ensure all error paths are exercised and properly logged during execution.
- All raised exceptions must either be caught or allowed to propagate with structured logging.
- Silent failure is prohibited. Any unhandled exception must be visible and documented.
- Validate against the criteria in `docs/pipeline/active/task_contract.md`.
- Log failures and changes in `docs/pipeline/active/memories.md`, then retry.

---

### **Phase 5: Full Validation and Testing**
- Run scripts on full-sample or edge-case real data.
- Use unit tests for Modules, log outputs for Flows and Scripts.
- Confirm all validation points in `docs/pipeline/active/task_contract.md`.
- Confirm that all error-handling routines behave as expected under failure conditions.
- Ensure any runtime errors that impact task outcomes are logged in `docs/pipeline/active/memories.md`, along with attempted resolutions.
- Verify that all scripts log runtime behavior to the `logs/` directory with correct levels (INFO, ERROR, etc.).
- Ensure that any exceptions raised are logged with full traceback.
- Confirm logging of start/end markers and key transitions in control flow.
- Mark the task as testing: `task-master set-status --id <id> --status testing`.

---

### **Phase 6: Closure and Documentation Sync**
- Mark the task as done: `task-master set-status --id <id> --status done`.

- **Archive current microtask**:
  - Move the content of `docs/pipeline/active/microtasks.md` to an archive file inside `docs/pipeline/active/microtasks_done/`.
  - Update `docs/pipeline/active/microtasks_log.md` with a reference to the archived file.

- **Update documentation**:
  - `docs/pipeline/active/memories.md` â†’ Log failures, discarded paths, and reasons.
  - `docs/pipeline/active/learning_by_doing.md` â†’ Note process improvements.
  - `docs/pipeline/active/task_contract.md` â†’ Confirm all conditions were met.

- Ensure the final state aligns with `docs/pipeline/pipeline_pickup.md`.

---

### **Core Principles (Mandatory)**
- Never develop without unit tests.
- Never execute changes without reviewing context via `docs/pipeline/pipeline_pickup.md`.
- Never modify logic without documenting changes and failures.
- Never assume a plan is valid until implementation validates it.
- Never mark a task done without:
  - Closing the microtask.
  - Logging learnings.
  - Documenting strategic knowledge in `docs/pipeline/active/memories.md`.

---

### **Quick Start Guide**

```bash
# 1. Setup the project for the first time
./setup_pipeline.sh

# 2. Check what you're working on
cat docs/pipeline/active/microtasks.md

# 3. See the project structure for a capability
tree data_processing/

# 4. List all tasks
task-master list

# 5. Get next recommended task
task-master next
```

---

### **Key Files Reference**

- **`docs/pipeline/pipeline_development.md`** â†’ This complete workflow guide.
- **`docs/pipeline/pipeline_pickup.md`** â†’ How to resume work after interruptions.
- **`docs/pipeline/active/microtasks.md`** â†’ Your current active work.
- **`docs/pipeline/active/memories.md`** â†’ Strategic knowledge and learnings.
- **`docs/pipeline/active/task_contract.md`** â†’ Success criteria and validation points.
- **`docs/rules/`** â†’ The single source of truth for all coding and process standards.

---

### **Setup Guide: Recreating the Pipeline Structure in a New Project**

When starting a new project, use these instructions to recreate the complete pipeline structure including all symlinks and directory organization.

#### **Automated Setup Script**
Create this script as `setup_pipeline.sh` in your project root:

```bash
#!/bin/bash
# TOFA-WDF Pipeline Setup Script v2.0

echo "Setting up TOFA-WDF pipeline structure..."

# Create root directory structure
mkdir -p config logs tasks shared_modules flows

# Create the full docs structure
mkdir -p docs/{external_knowledge,pipeline/tags/master/microtasks_done,rules,templates/config}
mkdir -p docs/pipeline/tags/.archive

# Create essential template and rule files
touch docs/rules/rule_{code_review_manual,cross_task_coordination,doc_guidelines,knowledge_sync,self_improve,test_data_policy,vscode_rules}.md
touch docs/templates/config/template_config.py
touch docs/templates/template_{learning_by_doing,memories,task_contract}.md

# Create essential tracking files within the master context
touch docs/pipeline/tags/master/{prd.md,microtasks.md,microtasks_log.md,memories.md,task_contract.md,learning_by_doing.md}

# Create the active symlink for the pipeline context
cd docs/pipeline/
ln -sfn tags/master/ active
cd ../../

echo "âœ… Pipeline structure created successfully!"
echo "-> Remember to copy 'docs/templates/config/template_config.py' to 'config/config.py' and fill it out."
```

#### **Usage Instructions**
```bash
# Make the script executable
chmod +x setup_pipeline.sh

# Run the setup for a new project
./setup_pipeline.sh
```

---

### **Advanced Workflow: The "Two-Step Sync" Protocol for Context Management**

To manage different features or experiments in isolation, Taskmaster uses "tags." To keep our TOFA-WDF documentation perfectly synchronized, we use a simple **Two-Step Sync** protocol.

#### **How to Create a New Feature Context (e.g., "feature-dashboard")**

This creates a new, isolated workspace for both tasks and documentation.

*   **Step 1 (Taskmaster):** Create the new tag in Taskmaster, copying from master.
    *   **Command:** `task-master add-tag feature-dashboard --copy-from master`
*   **Step 2 (TOFA-WDF):** Create the corresponding documentation context.
    *   **Command:** `cp -r docs/pipeline/tags/master/ docs/pipeline/tags/feature-dashboard/`

#### **How to Switch Between Contexts**

This activates a different workspace.

*   **Step 1 (Taskmaster):** Switch to the desired tag in Taskmaster.
    *   **Command:** `task-master use-tag feature-dashboard`
*   **Step 2 (TOFA-WDF):** Update the `active` symlink to point to the new context.
    *   **Commands (run from the `docs/pipeline/` directory):**
        1.  `rm active`
        2.  `ln -s tags/feature-dashboard/ active`

*All tools and file paths will now automatically use the `feature-dashboard` context.*

#### **How to Delete a Feature Context**

This safely archives the workspace.

*   **Step 1 (Taskmaster):** Delete the tag from Taskmaster.
    *   **Command:** `task-master delete-tag feature-dashboard`
*   **Step 2 (TOFA-WDF):** Archive the documentation context (we never delete it completely).
    *   **Commands:**
        1.  `mv docs/pipeline/tags/feature-dashboard/ docs/pipeline/tags/.archive/feature-dashboard_$(date +%F)`
```

========================================================================================================================

## FILE: `pipeline/tags/master/pipeline_pickup.md`

```markdown
# Pickup Roadmap: A Guide for Resuming Tasks

This document is the official guide for resuming work on any interrupted task efficiently and safely, ensuring that no context is lost.

To rebuild your mental context before writing a single line of code, follow these steps in the exact order presented:

### **Step 1: Recall the High-Level Purpose (The "What" and "Why")**
*   **Action**: Open and read the Product Requirements Document (PRD) of the active task.
*   **Location**: `pipeline/prd.md`
*   **Objective**: To re-internalize the high-level goal, requirements, and the value that the completed task provides.

ğŸ’¡ Tip: Recreate the development environment using `python -m venv .venv` and `pip install -r requirements.txt` before resuming implementation.

### **Step 2: Identify the Last Active State (The "Where I Was")**
*   **Action**: Open and read the active microtasks file. This is the most critical document, as it contains your last conscious thought on the problem.
*   **Location**: `pipeline/microtasks.md`
*   **Objective**: To understand the exact sub-objective you were working on, the plan you had proposed, and the constraints you had identified.

### **Step 3: Assimilate Past Experience (The "Mistakes" and "Lessons")**
*   **Action 3.1**: Review the log of decisions, dead ends, and discarded hypotheses.
*   **Location**: `pipeline/memories.md`
*   **Objective**: To avoid repeating past mistakes and to understand why certain structural decisions were made.

*   **Action 3.2**: Review the log of lessons learned and procedural improvements.
*   **Location**: `pipeline/learning_by_doing.md`
*   **Objective**: To remember if you discovered a smarter, faster, or more robust way of doing things so you can apply it now.

### **Step 4: Refresh the Final Goal (The "What Success Looks Like")**
*   **Action**: Consult the task's completion criteria.
*   **Location**: `pipeline/criterios_cierre.md`
*   **Objective**: To have a clear and measurable picture of the exact conditions your code must meet to consider the task finished.

### **Step 5: Resume the Development Cycle**
* **Action**: With all context restored, you are now ready to resume implementation.
* **Process Location**: Follow the workflow defined in `docs/pipeline/pipeline_development.md`.

Tip: Review the latest logs in `logs/` to confirm the last successful execution or identify where failure occurred.

---
This procedure ensures that every time you pick up your work, you do so with the same (or greater) clarity as when you left it.
```

========================================================================================================================

## FILE: `external_knowledge/know_docs_task-master.md`

```markdown
Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---

Search...
âŒ˜KAsk AI
Search...
Navigation
##### Welcome

##### Getting Started
  * Quick Start

##### Best Practices

##### Technical Capabilities

Welcome
# Introduction
Welcome to v1 of the Task Master Docs. Expect weekly updates as we expand and refine each section.
Weâ€™ve organized the docs into three sections depending on your experience level and goals:
### 
Getting Started - Jump in to [Quick Start](https://docs.task-master.dev/docs/getting-started/quick-start)
Designed for first-time users. Get set up, create your first PRD, and run your first task.
### 
Best Practices
Covers common workflows, strategic usage of commands, model configuration tips, and real-world usage patterns. Recommended for active users.
### 
Technical Capabilities
A detailed glossary of every root command and available capability â€” meant for power users and contributors.
* * *
Thanks for being here early. If you spot something broken or want to contribute, check out the [GitHub repo](https://github.com/eyaltoledano/claude-task-master). Have questions? Join our [Discord community](https://discord.gg/fWJkU7rf) to connect with other users and get help from the team.
Was this page helpful?
YesNo
Assistant
Responses are generated using AI and may contain mistakes.

---
```

========================================================================================================================

## FILE: `external_knowledge/know_task_master_integration.md`

```markdown
# Task Master Integration Guide (TOFA-WDF)

This guide explains how the **Task Master CLI** is integrated into the TOFA-WDF project structure. It maps the commands to your TOFA documents and execution flow, showing where they interact and how they are reflected.

---

## 1. Installation

Inside your working environment:

```bash
pip install task-master
```

If using conda:

```bash
conda activate <env_name>
pip install task-master
```

---

## 2. Initialization

Run once from the root of the project:

```bash
task init
```

This creates `.taskmaster/` and sets up basic project config.

---

## 3. CLI Commands and TOFA Interactions

| Task Master Command | Affected TOFA File(s) | Purpose |
|-------------------|----------------------|---------|
| `task prd "Task name"` | `pipeline/prd.md` + scaffold | Creates initial Product Requirement Document |
| `task parse_prd` | `pipeline/microtasks.md` (structure only) | Scaffolds sections for active microtask record |
| `task add_task "new subtask"` | none (CLI state only) | Adds a node to the task tree, not tracked in TOFA yet |
| `task set_task_status --task X --status Y` | `pipeline/microtasks_log.md` | Updates state reflected in logs and MCP-compatible tools |
| `task list` | CLI/interactive only | Lists task tree states and open/closed subtasks |

---

## 4. Roles and Separation of Responsibility

| Source | Responsible For |
|--------|------------------|
| `task prd` | Scaffolds project with TOFA structure |
| `pipeline/prd.md` | Defines the plan, objectives, and motivations |
| `pipeline/microtasks.md` | Describes the active microtask: includes current objective, its constraints, reasoning path, and expected result |
| `task parse_prd` | Can fill preliminary structure in microtasks.md, but does not define the plan |
| Developer | Manually writes the plan in prd.md and the current objective in microtasks.md |

---

## 5. Integration Lifecycle (Typical Use Case)

1. **Define PRD**
   â†“
   `task prd "Extract firm innovation patterns"`

2. **(Optional) Parse it**
   â†“
   `task parse_prd`

3. **Write implementation plan manually in:**
   - `pipeline/prd.md` (goals, constraints, rationale)
   - `pipeline/microtasks.md` (active microtask record)

4. **Work on code**
   â†“
   - `modules/` â†’ `orchestrators/` â†’ `flows/` â†’ `scripts/`

5. **Use status commands as needed:**
   - `task set_task_status --task "X" --status in-progress`

6. **Finalize, close task:**
   - `task set_task_status --task "X" --status done`

7. **Archive:**
   - Move to `microtasks_done/`
   - Log in `microtasks_log.md`
   - Document in `memories.md` and `learning_by_doing.md`

---

## 6. MCP Compatibility

You can integrate Task Master into LLM pipelines, IDE agents, or model coordination by defining:

```json
{
  "mcpServers": {
    "task": {
      "command": "task",
      "args": ["status"],
      "disabled": false,
      "autoApprove": [],
      "timeout": 60
    }
  }
}
```

This allows other tools to interact with your current task state.

---

## 7. Summary

Task Master is not a replacement for TOFA. It is a coordination assistant.

All plans, reasoning, and documentation must be written directly in:
- `pipeline/prd.md`
- `pipeline/microtasks.md`
- `pipeline/memories.md`
- `pipeline/learning_by_doing.md`

The task CLI helps track status, list subtasks, assign tags, and initiate PRDsâ€”but never generates logic or strategies.
```

========================================================================================================================

## FILE: `rules/rule_code_quality.md`

```markdown
# Rule: Code Quality & Automated Tooling

To ensure consistency, readability, and prevent common errors, this project mandates the use of automated code quality tools. These are not optional.

---

## **Note on `pyproject.toml` Location**

The `pyproject.toml` file **must** reside in the project's root directory. This is the industry-standard location that all modern Python tools expect. Do not move it.

---

## 1. Code Formatting: Black

-   **Tool:** [Black](https://github.com/psf/black), the uncompromising code formatter.
-   **Purpose:** Eliminates all arguments about code style. Black's style is non-negotiable and automatically applied.
-   **Configuration (`pyproject.toml`):**
    ```toml
    [tool.black]
    line-length = 88
    target-version = ['py310'] # Or your target Python version
    ```
-   **Usage:**
    ```bash
    # To format all files in the project
    poetry run black .
    ```

## 2. Linting: Ruff

-   **Tool:** [Ruff](https://github.com/astral-sh/ruff), an extremely fast Python linter.
-   **Purpose:** Catches a wide range of errors, from unused imports to logical mistakes, and enforces best practices (including PEP 8).
-   **Configuration (`pyproject.toml`):**
    ```toml
    [tool.ruff]
    line-length = 88
    select = [
        "E",  # pycodestyle errors
        "W",  # pycodestyle warnings
        "F",  # pyflakes
        "I",  # isort
        "C",  # flake8-comprehensions
        "B",  # flake8-bugbear
    ]
    ignore = ["E501"] # Ignored by Black's line wrapping
    ```
-   **Usage:**
    ```bash
    # To check all files for errors
    poetry run ruff .

    # To automatically fix fixable errors
    poetry run ruff . --fix
    ```

## 3. Pre-Commit Hooks (Recommended)

To automate these checks, it is highly recommended to use [pre-commit](https://pre-commit.com/). This ensures that no code that violates our quality standards is ever committed. A `.pre-commit-config.yaml` file should be present in the root directory.
```

========================================================================================================================

## FILE: `rules/rule_code_review_manual.md`

```markdown
# Manual Code Review Protocol (TOFA-WDF + Git)

## Review Approach

This project uses two layers of review:
1. Markdown-level traceability in:
   - `pipeline/microtasks.md`
   - `pipeline/memories.md`
2. Git diff-based visual review before committing.

## Review Checklist

- [ ] Each microtask must define purpose, logic plan, and constraints
- [ ] Code must match `microtasks.md` description
- [ ] Every new function must be accompanied by:
  - [ ] Functional inline comment above it
  - [ ] Unit test with real data
- [ ] No logic outside `simple/`, `orchestrators/`, `flows/`
- [ ] No undocumented deviation from microtask plan

No approval = no merge.

---

## Circular Dependency Policy

- Flows (`flows/`) must not reference task-local orchestrators directly.
- Task orchestrators must not import from flows.
- All dependencies are one-directional:
  - `simple/` â†’ `orchestrators/` â†’ `flows/` â†’ `scripts/`
```

========================================================================================================================

## FILE: `rules/rule_cross_task_coordination.md`

```markdown
# Cross-Task Coordination (TOFA-WDF)

## Strategy

- Use `flows/` as the only place where multiple tasks meet
- Never call a task-local orchestrator from another task

## Allowed Data Sharing

- Use `shared_modules/` for utilities reused across tasks
- Use `flows/` to coordinate outputs from multiple task orchestrators
- Pass outputs explicitly from one flow step to another, never via shared state

## Example Pattern

```python
# inside flows/integration_flow.py

from tasks.data_processing.functions.orchestrators.cleaning_pipeline import run_cleaning
from tasks.analysis.functions.orchestrators.analysis_pipeline import run_analysis

def integration_flow():
    clean_df = run_cleaning("data.csv")
    result = run_analysis(clean_df)
    ...
```

========================================================================================================================

## FILE: `rules/rule_dependency_management.md`

```markdown
# Rule: Dependency Management

To ensure a reproducible and stable environment, this project mandates a strict policy for managing external dependencies.

## 1. Tooling: Poetry

-   **Official Tool:** [Poetry](https://python-poetry.org/) is the sole authority for managing dependencies and virtual environments.
-   **Reasoning:** Poetry provides deterministic builds via the `poetry.lock` file, unified dependency and environment management, and a clean `pyproject.toml` standard.

## 2. Installing Dependencies

-   **Command:** Never use `pip install`. Always use Poetry to install dependencies from the lock file.
    ```bash
    # This installs the exact versions specified in poetry.lock
    poetry install
    ```

## 3. Adding a New Dependency

-   **Command:** Use the `poetry add` command. This will update both `pyproject.toml` and `poetry.lock`.
    ```bash
    # Add a new production dependency
    poetry add pandas

    # Add a new development-only dependency (e.g., for testing)
    poetry add pytest --group dev
    ```
-   **Action:** After adding a dependency, commit both the `pyproject.toml` and `poetry.lock` files together in the same commit.

## 4. Updating Dependencies

-   **Command:** Use `poetry update` to safely upgrade packages according to the version constraints in `pyproject.toml`.
    ```bash
    # Update all dependencies
    poetry update

    # Update a single package
    poetry update pandas
    ```
-   **Caution:** Run the test suite (`poetry run pytest`) immediately after updating to catch any breaking changes.
```

========================================================================================================================

## FILE: `rules/rule_doc_guidelines.md`

```markdown
# Documentation Guidelines (Minimal Style)

## Function Documentation
Use inline comments above each function:

```python
# This function loads a CSV and drops NA rows
def clean_data(df):
    ...
```

Deeper Reasoning or Process Logic

Use:
- pipeline/microtasks.md for active rationales
- pipeline/memories.md for rejected approaches or architecture changes
- pipeline/learning_by_doing.md for workflow/process lessons

---

## Naming Conventions

- Files must use `snake_case`
- Functions must use **action_noun** pattern, e.g., `load_csv`, `parse_metadata`, `validate_schema`
- File names must reflect purpose (e.g., `clean_data.py` not `utils.py`)
- No generic names like `helper.py`, `common.py`, `functions.py`
```

========================================================================================================================

## FILE: `rules/rule_knowledge_management.md`

```markdown
# Rule: Knowledge Management & Architecture Decisions

To prevent knowledge loss and ensure that our documentation remains valuable, we follow a strict protocol for managing long-term learnings and architectural decisions.

## 1. The Knowledge Synthesis & Archiving Protocol

-   **Problem:** `memories.md` and `learning_by_doing.md` can become bloated and unreadable over time, hiding valuable insights.
-   **Trigger:** This protocol is executed at the end of a major epic, a significant feature release, or at minimum, on a quarterly basis.
-   **Process:**
    1.  **Synthesize:** A designated developer reads through the active `memories.md` and `learning_by_doing.md`.
    2.  **Extract & Formalize:** Key strategic decisions, discarded architectural paths, and permanent process improvements are extracted and formalized into **Architecture Decision Records (ADRs)**. See below for details.
    3.  **Archive:** The content of the active `memories.md` and `learning_by_doing.md` is moved to a dated file in the archive (e.g., `docs/pipeline/active/archive/memories_q3_2025.md`).
    4.  **Reset:** The active `memories.md` and `learning_by_doing.md` are reset using their respective templates from `docs/templates/`.

## 2. Architecture Decision Records (ADRs)

-   **Purpose:** An ADR is a short document that captures a single, significant architectural decision. It is the permanent, high-level memory of the project.
-   **When to Create an ADR:**
    -   A decision that impacts the overall structure (e.g., choosing a new database, adopting a new library for a core function).
    -   A decision that has long-term consequences and trade-offs.
    -   A decision that a new developer must understand to grasp the "why" behind the codebase.
-   **Location:** ADRs are stored in a new top-level directory: `docs/adr/`.
-   **Format:** Create new ADRs by copying `docs/templates/template_adr.md`.
```

========================================================================================================================

## FILE: `rules/rule_knowledge_sync_policy.md`

```markdown
# Knowledge Synchronization and Validation Policy

This document mandates how project-specific rules are updated and used, ensuring all development aligns with the latest best practices. The `docs/rules/` directory is the single source of truth.

## The Rule Update Workflow

1.  **Documentation-First:** Any change to a coding standard **must** first be documented by editing the relevant file in `docs/rules/`. The commit message for this change should clearly state the new rule.
2.  **Mandatory AI Validation:** Before applying any new or changed rule, the AI agent **must** first validate its understanding of the change. This is done by running a `research` query targeting the specific rule file.
    *   **Purpose:** This step forces the AI to re-read the rule and confirms its context is up-to-date, preventing it from using outdated, cached knowledge.
    *   **Example Command:** `task-master research --query="Explain the new required format for function docstrings." --files="docs/rules/doc_guidelines.md"`
3.  **Informed Application:** Only after the AI receives a correct summary from its research query can it proceed to apply the new pattern to the codebase.
```

========================================================================================================================

## FILE: `rules/rule_security_guidelines.md`

```markdown
# Rule: Security Guidelines

Security is not an afterthought; it is a core design principle. All code must adhere to the following guidelines.

## 1. Secrets Management

-   **Principle:** Secrets (API keys, tokens, passwords) **must never** be hardcoded or committed to the repository.
-   **Mechanism:**
    1.  All secrets must be defined as environment variables in a local `.env` file at the project root.
    2.  The `.env` file is listed in `.gitignore` and must never be committed.
    3.  The `config/config.py` file is the only place where environment variables are read into the application. Other parts of the code must import them from `config`.

## 2. Input Validation

-   **Principle:** Never trust input.
-   **Action:** The assumption "All inputs are assumed to be pre-validated" is a temporary convenience for isolated development. For any function that could potentially receive external data (file uploads, API calls, user-provided parameters), perform explicit validation.
    -   Check data types (e.g., using Pydantic or simple type assertions).
    -   Sanitize inputs to prevent injection attacks.
    -   Validate file paths to prevent directory traversal.

## 3. Dependency Vulnerability Scanning

-   **Principle:** Our code is only as secure as its dependencies.
-   **Action:** Regularly scan project dependencies for known vulnerabilities.
-   **Recommended Tool:** Use `pip-audit` or `safety` via Poetry.
    ```bash
    # Install pip-audit
    pip install pip-audit

    # Run the audit against the Poetry environment
    poetry run pip-audit
    ```
-   **Policy:** Any "High" or "Critical" vulnerability must be addressed immediately, either by updating the package or replacing it.
```

========================================================================================================================

## FILE: `rules/rule_self_improve.md`

```markdown
---
description: Guidelines for continuously improving VS Code rules based on emerging code patterns and best practices.
applyTo: "**/*"
alwaysApply: true
---

- **Rule Improvement Triggers:**
  - New code patterns not covered by existing rules
  - Repeated similar implementations across files
  - Common error patterns that could be prevented
  - New libraries or tools being used consistently
  - Emerging best practices in the codebase

- **Analysis Process:**
  - Compare new code with existing rules
  - Identify patterns that should be standardized
  - Look for references to external documentation
  - Check for consistent error handling patterns
  - Monitor test patterns and coverage

- **Rule Updates:**
  - **Add New Rules When:**
    - A new technology/pattern is used in 3+ files
    - Common bugs could be prevented by a rule
    - Code reviews repeatedly mention the same feedback
    - New security or performance patterns emerge

  - **Modify Existing Rules When:**
    - Better examples exist in the codebase
    - Additional edge cases are discovered
    - Related rules have been updated
    - Implementation details have changed

- **Example Pattern Recognition:**
  ```typescript
  // If you see repeated patterns like:
  const data = await prisma.user.findMany({
    select: { id: true, email: true },
    where: { status: 'ACTIVE' }
  });
  
  // Consider adding to [prisma.md](.github/instructions/prisma.md):
  // - Standard select fields
  // - Common where conditions
  // - Performance optimization patterns
  ```

- **Rule Quality Checks:**
  - Rules should be actionable and specific
  - Examples should come from actual code
  - References should be up to date
  - Patterns should be consistently enforced

- **Continuous Improvement:**
  - Monitor code review comments
  - Track common development questions
  - Update rules after major refactors
  - Add links to relevant documentation
  - Cross-reference related rules

- **Rule Deprecation:**
  - Mark outdated patterns as deprecated
  - Remove rules that no longer apply
  - Update references to deprecated rules
  - Document migration paths for old patterns

- **Documentation Updates:**
  - Keep examples synchronized with code
  - Update references to external docs
  - Maintain links between related rules
  - Document breaking changes
Follow [vscode_rules.md](.github/instructions/vscode_rules.md) for proper rule formatting and structure.
```

========================================================================================================================

## FILE: `rules/rule_test_data_policy.md`

```markdown
# Test Data Management Policy

## Folder Structure
Each task stores test samples in:

tasks/<task_name>/test_data/

## Requirements
- Use real data samples only (no synthetic)
- Prefer `.csv` or `.json` format
- Redact if needed, but preserve structure
- Document assumptions in `microtasks.md`

## Maintenance
- Each module's unit test must operate on a real example from this folder
- No function is valid without test coverage using data from here
```

========================================================================================================================

## FILE: `rules/rule_vscode_rules.md`

```markdown
---
description: Guidelines for creating and maintaining VS Code rules to ensure consistency and effectiveness.
applyTo: ".github/instructions/*.md"
alwaysApply: true
---

- **Required Rule Structure:**
  ```markdown
  ---
  description: Clear, one-line description of what the rule enforces
  globs: path/to/files/*.ext, other/path/**/*
  alwaysApply: boolean
  ---

  - **Main Points in Bold**
    - Sub-points with details
    - Examples and explanations
  ```

- **File References:**
  - Use `[filename](mdc:path/to/file)` ([filename](mdc:filename)) to reference files
  - Example: [prisma.md](.github/instructions/prisma.md) for rule references
  - Example: [schema.prisma](mdc:prisma/schema.prisma) for code references

- **Code Examples:**
  - Use language-specific code blocks
  ```typescript
  // âœ… DO: Show good examples
  const goodExample = true;
  
  // âŒ DON'T: Show anti-patterns
  const badExample = false;
  ```

- **Rule Content Guidelines:**
  - Start with high-level overview
  - Include specific, actionable requirements
  - Show examples of correct implementation
  - Reference existing code when possible
  - Keep rules DRY by referencing other rules

- **Rule Maintenance:**
  - Update rules when new patterns emerge
  - Add examples from actual codebase
  - Remove outdated patterns
  - Cross-reference related rules

- **Best Practices:**
  - Use bullet points for clarity
  - Keep descriptions concise
  - Include both DO and DON'T examples
  - Reference actual code over theoretical examples
  - Use consistent formatting across rules
```

========================================================================================================================

## FILE: `templates/template_adr.md`

```markdown
# ADR-XXX: [Title of Decision]

-   **Status:** [Proposed | Accepted | Deprecated | Superseded by ADR-YYY]
-   **Date:** [YYYY-MM-DD]

## Context

*What is the issue that we're seeing that is motivating this decision or change? What is the context in which we are making this decision?*

---

## Decision

*What is the change that we're proposing and/or doing? This should be stated in full sentences, active voice.*

---

## Consequences

*What becomes easier or more difficult to do because of this change? What are the positive, negative, and neutral consequences? This section is critical for future decision-making.*
```

========================================================================================================================

## FILE: `templates/template_learning_by_doing.md`

```markdown
# Learning by Doing

This file captures workflow and process lessons learned through implementation.

### [2025-07-23] Formalizing Implicit Practices

Documented minimal responses to perceived gaps raised by external reviewer:
- Adopted markdown protocols to preempt future critiques
- Standardized our inline and process documentation strategy

Outcome: full compliance with no added weight.

### [2025-07-23] Structural Guidance Formalized

Captured and resolved key missing structural guarantees:
- Defined data test layout and naming expectations
- Codified file/function naming
- Locked architecture boundaries for flows and orchestrators

This makes TOFA-WDF auditable by external reviewers without increasing workload.
### [2025-07-23] CLI/TOFA boundary made explicit

Clarified that `task` only scaffolds and tracks state. Human writes the plan and logic in `prd.md` and `microtasks.md`.
```

========================================================================================================================

## FILE: `templates/template_memories.md`

```markdown
# Pipeline Memories

This file contains rejected approaches, architecture changes, and important decisions.

### [2025-07-23] Boss Feedback: Practical Gaps

Added minimalistic responses to six reported gaps:
- Performance: clarified in `task_contract.md`
- Security: input assumptions clarified
- Documentation: policy added in `docs/`
- Review Process: markdown + git combo formalized

No structural changes to workflow or logic.

### [2025-07-23] Structural Design Hardening

Documented protocol to prevent:
- circular dependencies across layers
- test data mismanagement
- cross-task ambiguity
- inconsistency in naming

No need to refactor existing code. Future work adheres to these modular protocols.
### [2025-07-23] Task Master CLI clarified

Integrated CLI-to-TOFA-WDF interaction mapping in `docs/task_master_integration.md`, distinguishing between execution, planning, and coordination.
```

========================================================================================================================

## FILE: `templates/template_task_contract.md`

```markdown
# Task Contract

This document defines the contract for data processing tasks in this project.

## Performance Guidelines (Optional, for Data Tasks)

- Expected runtime: under 60 seconds for 1K rows
- Memory usage: not a concern unless explicitly logged
- Batch vs streaming behavior: pure batch unless documented

---

## Input Validation / Security

- All inputs are assumed to be pre-validated or internal
- No user-facing API; no injection risk assumed
- Input structure assumptions must be noted in `microtasks.md` or inline comments
```

========================================================================================================================

## FILE: `templates/config/template_config.py`

```markdown
# config/config.py

import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# ==== PATHS ====
DATA_DIR = "data/"
LOGS_DIR = "logs/"
OUTPUT_DIR = "outputs/"

# ==== PARAMETERS ====
DEFAULT_INPUT_FILE = os.getenv("DEFAULT_INPUT_FILE", "input.csv")
USE_CACHE = os.getenv("USE_CACHE", "True") == "True"
VERBOSE_MODE = os.getenv("VERBOSE_MODE", "False") == "True"

# ==== SECRETS ====
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DROPBOX_TOKEN = os.getenv("DROPBOX_TOKEN")
```

========================================================================================================================

## FILE: `../.github/instructions/dev_workflow.md`

```markdown
---
description: Guide for using Taskmaster to manage task-driven development workflows
applyTo: "**/*"
alwaysApply: true
---

# Taskmaster Development Workflow

This guide outlines the standard process for using Taskmaster to manage software development projects. It is written as a set of instructions for you, the AI agent.

- **Your Default Stance**: For most projects, the user can work directly within the `master` task context. Your initial actions should operate on this default context unless a clear pattern for multi-context work emerges.
- **Your Goal**: Your role is to elevate the user's workflow by intelligently introducing advanced features like **Tagged Task Lists** when you detect the appropriate context. Do not force tags on the user; suggest them as a helpful solution to a specific need.

## The Basic Loop
The fundamental development cycle you will facilitate is:
1.  **`list`**: Show the user what needs to be done.
2.  **`next`**: Help the user decide what to work on.
3.  **`show <id>`**: Provide details for a specific task.
4.  **`expand <id>`**: Break down a complex task into smaller, manageable subtasks.
5.  **Implement**: The user writes the code and tests.
6.  **`update-subtask`**: Log progress and findings on behalf of the user.
7.  **`set-status`**: Mark tasks and subtasks as `done` as work is completed.
8.  **Repeat**.

All your standard command executions should operate on the user's current task context, which defaults to `master`.

---

## Standard Development Workflow Process

### Simple Workflow (Default Starting Point)

For new projects or when users are getting started, operate within the `master` tag context:

-   Start new projects by running `initialize_project` tool / `task-master init` or `parse_prd` / `task-master parse-prd --input='<prd-file.txt>'` (see @`taskmaster.md`) to generate initial tasks.json with tagged structure
-   Configure rule sets during initialization with `--rules` flag (e.g., `task-master init --rules vscode,windsurf`) or manage them later with `task-master rules add/remove` commands  
-   Begin coding sessions with `get_tasks` / `task-master list` (see @`taskmaster.md`) to see current tasks, status, and IDs
-   Determine the next task to work on using `next_task` / `task-master next` (see @`taskmaster.md`)
-   Analyze task complexity with `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) before breaking down tasks
-   Review complexity report using `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`)
-   Select tasks based on dependencies (all marked 'done'), priority level, and ID order
-   View specific task details using `get_task` / `task-master show <id>` (see @`taskmaster.md`) to understand implementation requirements
-   Break down complex tasks using `expand_task` / `task-master expand --id=<id> --force --research` (see @`taskmaster.md`) with appropriate flags like `--force` (to replace existing subtasks) and `--research`
-   Implement code following task details, dependencies, and project standards
-   Mark completed tasks with `set_task_status` / `task-master set-status --id=<id> --status=done` (see @`taskmaster.md`)
-   Update dependent tasks when implementation differs from original plan using `update` / `task-master update --from=<id> --prompt="..."` or `update_task` / `task-master update-task --id=<id> --prompt="..."` (see @`taskmaster.md`)

---

## Leveling Up: Agent-Led Multi-Context Workflows

While the basic workflow is powerful, your primary opportunity to add value is by identifying when to introduce **Tagged Task Lists**. These patterns are your tools for creating a more organized and efficient development environment for the user, especially if you detect agentic or parallel development happening across the same session.

**Critical Principle**: Most users should never see a difference in their experience. Only introduce advanced workflows when you detect clear indicators that the project has evolved beyond simple task management.

### When to Introduce Tags: Your Decision Patterns

Here are the patterns to look for. When you detect one, you should propose the corresponding workflow to the user.

#### Pattern 1: Simple Git Feature Branching
This is the most common and direct use case for tags.

- **Trigger**: The user creates a new git branch (e.g., `git checkout -b feature/user-auth`).
- **Your Action**: Propose creating a new tag that mirrors the branch name to isolate the feature's tasks from `master`.
- **Your Suggested Prompt**: *"I see you've created a new branch named 'feature/user-auth'. To keep all related tasks neatly organized and separate from your main list, I can create a corresponding task tag for you. This helps prevent merge conflicts in your `tasks.json` file later. Shall I create the 'feature-user-auth' tag?"*
- **Tool to Use**: `task-master add-tag --from-branch`

#### Pattern 2: Team Collaboration
- **Trigger**: The user mentions working with teammates (e.g., "My teammate Alice is handling the database schema," or "I need to review Bob's work on the API.").
- **Your Action**: Suggest creating a separate tag for the user's work to prevent conflicts with shared master context.
- **Your Suggested Prompt**: *"Since you're working with Alice, I can create a separate task context for your work to avoid conflicts. This way, Alice can continue working with the master list while you have your own isolated context. When you're ready to merge your work, we can coordinate the tasks back to master. Shall I create a tag for your current work?"*
- **Tool to Use**: `task-master add-tag my-work --copy-from-current --description="My tasks while collaborating with Alice"`

#### Pattern 3: Experiments or Risky Refactors
- **Trigger**: The user wants to try something that might not be kept (e.g., "I want to experiment with switching our state management library," or "Let's refactor the old API module, but I want to keep the current tasks as a reference.").
- **Your Action**: Propose creating a sandboxed tag for the experimental work.
- **Your Suggested Prompt**: *"This sounds like a great experiment. To keep these new tasks separate from our main plan, I can create a temporary 'experiment-zustand' tag for this work. If we decide not to proceed, we can simply delete the tag without affecting the main task list. Sound good?"*
- **Tool to Use**: `task-master add-tag experiment-zustand --description="Exploring Zustand migration"`

#### Pattern 4: Large Feature Initiatives (PRD-Driven)
This is a more structured approach for significant new features or epics.

- **Trigger**: The user describes a large, multi-step feature that would benefit from a formal plan.
- **Your Action**: Propose a comprehensive, PRD-driven workflow.
- **Your Suggested Prompt**: *"This sounds like a significant new feature. To manage this effectively, I suggest we create a dedicated task context for it. Here's the plan: I'll create a new tag called 'feature-xyz', then we can draft a Product Requirements Document (PRD) together to scope the work. Once the PRD is ready, I'll automatically generate all the necessary tasks within that new tag. How does that sound?"*
- **Your Implementation Flow**:
    1.  **Create an empty tag**: `task-master add-tag feature-xyz --description "Tasks for the new XYZ feature"`. You can also start by creating a git branch if applicable, and then create the tag from that branch.
    2.  **Collaborate & Create PRD**: Work with the user to create a detailed PRD file (e.g., `.taskmaster/docs/feature-xyz-prd.txt`).
    3.  **Parse PRD into the new tag**: `task-master parse-prd .taskmaster/docs/feature-xyz-prd.txt --tag feature-xyz`
    4.  **Prepare the new task list**: Follow up by suggesting `analyze-complexity` and `expand-all` for the newly created tasks within the `feature-xyz` tag.

#### Pattern 5: Version-Based Development
Tailor your approach based on the project maturity indicated by tag names.

- **Prototype/MVP Tags** (`prototype`, `mvp`, `poc`, `v0.x`):
  - **Your Approach**: Focus on speed and functionality over perfection
  - **Task Generation**: Create tasks that emphasize "get it working" over "get it perfect"
  - **Complexity Level**: Lower complexity, fewer subtasks, more direct implementation paths
  - **Research Prompts**: Include context like "This is a prototype - prioritize speed and basic functionality over optimization"
  - **Example Prompt Addition**: *"Since this is for the MVP, I'll focus on tasks that get core functionality working quickly rather than over-engineering."*

- **Production/Mature Tags** (`v1.0+`, `production`, `stable`):
  - **Your Approach**: Emphasize robustness, testing, and maintainability
  - **Task Generation**: Include comprehensive error handling, testing, documentation, and optimization
  - **Complexity Level**: Higher complexity, more detailed subtasks, thorough implementation paths
  - **Research Prompts**: Include context like "This is for production - prioritize reliability, performance, and maintainability"
  - **Example Prompt Addition**: *"Since this is for production, I'll ensure tasks include proper error handling, testing, and documentation."*

### Advanced Workflow (Tag-Based & PRD-Driven)

**When to Transition**: Recognize when the project has evolved (or has initiated a project which existing code) beyond simple task management. Look for these indicators:
- User mentions teammates or collaboration needs
- Project has grown to 15+ tasks with mixed priorities
- User creates feature branches or mentions major initiatives
- User initializes Taskmaster on an existing, complex codebase
- User describes large features that would benefit from dedicated planning

**Your Role in Transition**: Guide the user to a more sophisticated workflow that leverages tags for organization and PRDs for comprehensive planning.

#### Master List Strategy (High-Value Focus)
Once you transition to tag-based workflows, the `master` tag should ideally contain only:
- **High-level deliverables** that provide significant business value
- **Major milestones** and epic-level features
- **Critical infrastructure** work that affects the entire project
- **Release-blocking** items

**What NOT to put in master**:
- Detailed implementation subtasks (these go in feature-specific tags' parent tasks)
- Refactoring work (create dedicated tags like `refactor-auth`)
- Experimental features (use `experiment-*` tags)
- Team member-specific tasks (use person-specific tags)

#### PRD-Driven Feature Development

**For New Major Features**:
1. **Identify the Initiative**: When user describes a significant feature
2. **Create Dedicated Tag**: `add_tag feature-[name] --description="[Feature description]"`
3. **Collaborative PRD Creation**: Work with user to create comprehensive PRD in `.taskmaster/docs/feature-[name]-prd.txt`
4. **Parse & Prepare**: 
   - `parse_prd .taskmaster/docs/feature-[name]-prd.txt --tag=feature-[name]`
   - `analyze_project_complexity --tag=feature-[name] --research`
   - `expand_all --tag=feature-[name] --research`
5. **Add Master Reference**: Create a high-level task in `master` that references the feature tag

**For Existing Codebase Analysis**:
When users initialize Taskmaster on existing projects:
1. **Codebase Discovery**: Use your native tools for producing deep context about the code base. You may use `research` tool with `--tree` and `--files` to collect up to date information using the existing architecture as context.
2. **Collaborative Assessment**: Work with user to identify improvement areas, technical debt, or new features
3. **Strategic PRD Creation**: Co-author PRDs that include:
   - Current state analysis (based on your codebase research)
   - Proposed improvements or new features
   - Implementation strategy considering existing code
4. **Tag-Based Organization**: Parse PRDs into appropriate tags (`refactor-api`, `feature-dashboard`, `tech-debt`, etc.)
5. **Master List Curation**: Keep only the most valuable initiatives in master

The parse-prd's `--append` flag enables the user to parse multiple PRDs within tags or across tags. PRDs should be focused and the number of tasks they are parsed into should be strategically chosen relative to the PRD's complexity and level of detail.

### Workflow Transition Examples

**Example 1: Simple â†’ Team-Based**
```
User: "Alice is going to help with the API work"
Your Response: "Great! To avoid conflicts, I'll create a separate task context for your work. Alice can continue with the master list while you work in your own context. When you're ready to merge, we can coordinate the tasks back together."
Action: add_tag my-api-work --copy-from-current --description="My API tasks while collaborating with Alice"
```

**Example 2: Simple â†’ PRD-Driven**
```
User: "I want to add a complete user dashboard with analytics, user management, and reporting"
Your Response: "This sounds like a major feature that would benefit from detailed planning. Let me create a dedicated context for this work and we can draft a PRD together to ensure we capture all requirements."
Actions: 
1. add_tag feature-dashboard --description="User dashboard with analytics and management"
2. Collaborate on PRD creation
3. parse_prd dashboard-prd.txt --tag=feature-dashboard
4. Add high-level "User Dashboard" task to master
```

**Example 3: Existing Project â†’ Strategic Planning**
```
User: "I just initialized Taskmaster on my existing React app. It's getting messy and I want to improve it."
Your Response: "Let me research your codebase to understand the current architecture, then we can create a strategic plan for improvements."
Actions:
1. research "Current React app architecture and improvement opportunities" --tree --files=src/
2. Collaborate on improvement PRD based on findings
3. Create tags for different improvement areas (refactor-components, improve-state-management, etc.)
4. Keep only major improvement initiatives in master
```

---

## Primary Interaction: MCP Server vs. CLI

Taskmaster offers two primary ways to interact:

1.  **MCP Server (Recommended for Integrated Tools)**:
    - For AI agents and integrated development environments (like VS Code), interacting via the **MCP server is the preferred method**.
    - The MCP server exposes Taskmaster functionality through a set of tools (e.g., `get_tasks`, `add_subtask`).
    - This method offers better performance, structured data exchange, and richer error handling compared to CLI parsing.
    - Refer to @`mcp.md` for details on the MCP architecture and available tools.
    - A comprehensive list and description of MCP tools and their corresponding CLI commands can be found in @`taskmaster.md`.
    - **Restart the MCP server** if core logic in `scripts/modules` or MCP tool/direct function definitions change.
    - **Note**: MCP tools fully support tagged task lists with complete tag management capabilities.

2.  **`task-master` CLI (For Users & Fallback)**:
    - The global `task-master` command provides a user-friendly interface for direct terminal interaction.
    - It can also serve as a fallback if the MCP server is inaccessible or a specific function isn't exposed via MCP.
    - Install globally with `npm install -g task-master-ai` or use locally via `npx task-master-ai ...`.
    - The CLI commands often mirror the MCP tools (e.g., `task-master list` corresponds to `get_tasks`).
    - Refer to @`taskmaster.md` for a detailed command reference.
    - **Tagged Task Lists**: CLI fully supports the new tagged system with seamless migration.

## How the Tag System Works (For Your Reference)

- **Data Structure**: Tasks are organized into separate contexts (tags) like "master", "feature-branch", or "v2.0".
- **Silent Migration**: Existing projects automatically migrate to use a "master" tag with zero disruption.
- **Context Isolation**: Tasks in different tags are completely separate. Changes in one tag do not affect any other tag.
- **Manual Control**: The user is always in control. There is no automatic switching. You facilitate switching by using `use-tag <name>`.
- **Full CLI & MCP Support**: All tag management commands are available through both the CLI and MCP tools for you to use. Refer to @`taskmaster.md` for a full command list.

---

## Task Complexity Analysis

-   Run `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) for comprehensive analysis
-   Review complexity report via `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`) for a formatted, readable version.
-   Focus on tasks with highest complexity scores (8-10) for detailed breakdown
-   Use analysis results to determine appropriate subtask allocation
-   Note that reports are automatically used by the `expand_task` tool/command

## Task Breakdown Process

-   Use `expand_task` / `task-master expand --id=<id>`. It automatically uses the complexity report if found, otherwise generates default number of subtasks.
-   Use `--num=<number>` to specify an explicit number of subtasks, overriding defaults or complexity report recommendations.
-   Add `--research` flag to leverage Perplexity AI for research-backed expansion.
-   Add `--force` flag to clear existing subtasks before generating new ones (default is to append).
-   Use `--prompt="<context>"` to provide additional context when needed.
-   Review and adjust generated subtasks as necessary.
-   Use `expand_all` tool or `task-master expand --all` to expand multiple pending tasks at once, respecting flags like `--force` and `--research`.
-   If subtasks need complete replacement (regardless of the `--force` flag on `expand`), clear them first with `clear_subtasks` / `task-master clear-subtasks --id=<id>`.

## Implementation Drift Handling

-   When implementation differs significantly from planned approach
-   When future tasks need modification due to current implementation choices
-   When new dependencies or requirements emerge
-   Use `update` / `task-master update --from=<futureTaskId> --prompt='<explanation>\nUpdate context...' --research` to update multiple future tasks.
-   Use `update_task` / `task-master update-task --id=<taskId> --prompt='<explanation>\nUpdate context...' --research` to update a single specific task.

## Task Status Management

-   Use 'pending' for tasks ready to be worked on
-   Use 'done' for completed and verified tasks
-   Use 'deferred' for postponed tasks
-   Add custom status values as needed for project-specific workflows

## Task Structure Fields

- **id**: Unique identifier for the task (Example: `1`, `1.1`)
- **title**: Brief, descriptive title (Example: `"Initialize Repo"`)
- **description**: Concise summary of what the task involves (Example: `"Create a new repository, set up initial structure."`)
- **status**: Current state of the task (Example: `"pending"`, `"done"`, `"deferred"`)
- **dependencies**: IDs of prerequisite tasks (Example: `[1, 2.1]`)
    - Dependencies are displayed with status indicators (âœ… for completed, â±ï¸ for pending)
    - This helps quickly identify which prerequisite tasks are blocking work
- **priority**: Importance level (Example: `"high"`, `"medium"`, `"low"`)
- **details**: In-depth implementation instructions (Example: `"Use GitHub client ID/secret, handle callback, set session token."`) 
- **testStrategy**: Verification approach (Example: `"Deploy and call endpoint to confirm 'Hello World' response."`) 
- **subtasks**: List of smaller, more specific tasks (Example: `[{"id": 1, "title": "Configure OAuth", ...}]`) 
- Refer to task structure details (previously linked to `tasks.md`).

## Configuration Management (Updated)

Taskmaster configuration is managed through two main mechanisms:

1.  **`.taskmaster/config.json` File (Primary):**
    *   Located in the project root directory.
    *   Stores most configuration settings: AI model selections (main, research, fallback), parameters (max tokens, temperature), logging level, default subtasks/priority, project name, etc.
    *   **Tagged System Settings**: Includes `global.defaultTag` (defaults to "master") and `tags` section for tag management configuration.
    *   **Managed via `task-master models --setup` command.** Do not edit manually unless you know what you are doing.
    *   **View/Set specific models via `task-master models` command or `models` MCP tool.**
    *   Created automatically when you run `task-master models --setup` for the first time or during tagged system migration.

2.  **Environment Variables (`.env` / `mcp.json`):**
    *   Used **only** for sensitive API keys and specific endpoint URLs.
    *   Place API keys (one per provider) in a `.env` file in the project root for CLI usage.
    *   For MCP/VS Code integration, configure these keys in the `env` section of `.vscode/mcp.json`.
    *   Available keys/variables: See `assets/env.example` or the Configuration section in the command reference (previously linked to `taskmaster.md`).

3.  **`.taskmaster/state.json` File (Tagged System State):**
    *   Tracks current tag context and migration status.
    *   Automatically created during tagged system migration.
    *   Contains: `currentTag`, `lastSwitched`, `migrationNoticeShown`.

**Important:** Non-API key settings (like model selections, `MAX_TOKENS`, `TASKMASTER_LOG_LEVEL`) are **no longer configured via environment variables**. Use the `task-master models` command (or `--setup` for interactive configuration) or the `models` MCP tool.
**If AI commands FAIL in MCP** verify that the API key for the selected provider is present in the `env` section of `.vscode/mcp.json`.
**If AI commands FAIL in CLI** verify that the API key for the selected provider is present in the `.env` file in the root of the project.

## Rules Management

Taskmaster supports multiple AI coding assistant rule sets that can be configured during project initialization or managed afterward:

- **Available Profiles**: Claude Code, Cline, Codex, VS Code, Roo Code, Trae, Windsurf (claude, cline, codex, vscode, roo, trae, windsurf)
- **During Initialization**: Use `task-master init --rules vscode,windsurf` to specify which rule sets to include
- **After Initialization**: Use `task-master rules add <profiles>` or `task-master rules remove <profiles>` to manage rule sets
- **Interactive Setup**: Use `task-master rules setup` to launch an interactive prompt for selecting rule profiles
- **Default Behavior**: If no `--rules` flag is specified during initialization, all available rule profiles are included
- **Rule Structure**: Each profile creates its own directory (e.g., `.github/instructions`, `.roo/rules`) with appropriate configuration files

## Determining the Next Task

- Run `next_task` / `task-master next` to show the next task to work on.
- The command identifies tasks with all dependencies satisfied
- Tasks are prioritized by priority level, dependency count, and ID
- The command shows comprehensive task information including:
    - Basic task details and description
    - Implementation details
    - Subtasks (if they exist)
    - Contextual suggested actions
- Recommended before starting any new development work
- Respects your project's dependency structure
- Ensures tasks are completed in the appropriate sequence
- Provides ready-to-use commands for common task actions

## Viewing Specific Task Details

- Run `get_task` / `task-master show <id>` to view a specific task.
- Use dot notation for subtasks: `task-master show 1.2` (shows subtask 2 of task 1)
- Displays comprehensive information similar to the next command, but for a specific task
- For parent tasks, shows all subtasks and their current status
- For subtasks, shows parent task information and relationship
- Provides contextual suggested actions appropriate for the specific task
- Useful for examining task details before implementation or checking status

## Managing Task Dependencies

- Use `add_dependency` / `task-master add-dependency --id=<id> --depends-on=<id>` to add a dependency.
- Use `remove_dependency` / `task-master remove-dependency --id=<id> --depends-on=<id>` to remove a dependency.
- The system prevents circular dependencies and duplicate dependency entries
- Dependencies are checked for existence before being added or removed
- Task files are automatically regenerated after dependency changes
- Dependencies are visualized with status indicators in task listings and files

## Task Reorganization

- Use `move_task` / `task-master move --from=<id> --to=<id>` to move tasks or subtasks within the hierarchy
- This command supports several use cases:
  - Moving a standalone task to become a subtask (e.g., `--from=5 --to=7`)
  - Moving a subtask to become a standalone task (e.g., `--from=5.2 --to=7`) 
  - Moving a subtask to a different parent (e.g., `--from=5.2 --to=7.3`)
  - Reordering subtasks within the same parent (e.g., `--from=5.2 --to=5.4`)
  - Moving a task to a new, non-existent ID position (e.g., `--from=5 --to=25`)
  - Moving multiple tasks at once using comma-separated IDs (e.g., `--from=10,11,12 --to=16,17,18`)
- The system includes validation to prevent data loss:
  - Allows moving to non-existent IDs by creating placeholder tasks
  - Prevents moving to existing task IDs that have content (to avoid overwriting)
  - Validates source tasks exist before attempting to move them
- The system maintains proper parent-child relationships and dependency integrity
- Task files are automatically regenerated after the move operation
- This provides greater flexibility in organizing and refining your task structure as project understanding evolves
- This is especially useful when dealing with potential merge conflicts arising from teams creating tasks on separate branches. Solve these conflicts very easily by moving your tasks and keeping theirs.

## Iterative Subtask Implementation

Once a task has been broken down into subtasks using `expand_task` or similar methods, follow this iterative process for implementation:

1.  **Understand the Goal (Preparation):**
    *   Use `get_task` / `task-master show <subtaskId>` (see @`taskmaster.md`) to thoroughly understand the specific goals and requirements of the subtask.

2.  **Initial Exploration & Planning (Iteration 1):**
    *   This is the first attempt at creating a concrete implementation plan.
    *   Explore the codebase to identify the precise files, functions, and even specific lines of code that will need modification.
    *   Determine the intended code changes (diffs) and their locations.
    *   Gather *all* relevant details from this exploration phase.

3.  **Log the Plan:**
    *   Run `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<detailed plan>'`.
    *   Provide the *complete and detailed* findings from the exploration phase in the prompt. Include file paths, line numbers, proposed diffs, reasoning, and any potential challenges identified. Do not omit details. The goal is to create a rich, timestamped log within the subtask's `details`.

4.  **Verify the Plan:**
    *   Run `get_task` / `task-master show <subtaskId>` again to confirm that the detailed implementation plan has been successfully appended to the subtask's details.

5.  **Begin Implementation:**
    *   Set the subtask status using `set_task_status` / `task-master set-status --id=<subtaskId> --status=in-progress`.
    *   Start coding based on the logged plan.

6.  **Refine and Log Progress (Iteration 2+):**
    *   As implementation progresses, you will encounter challenges, discover nuances, or confirm successful approaches.
    *   **Before appending new information**: Briefly review the *existing* details logged in the subtask (using `get_task` or recalling from context) to ensure the update adds fresh insights and avoids redundancy.
    *   **Regularly** use `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<update details>\n- What worked...\n- What didn't work...'` to append new findings.
    *   **Crucially, log:**
        *   What worked ("fundamental truths" discovered).
        *   What didn't work and why (to avoid repeating mistakes).
        *   Specific code snippets or configurations that were successful.
        *   Decisions made, especially if confirmed with user input.
        *   Any deviations from the initial plan and the reasoning.
    *   The objective is to continuously enrich the subtask's details, creating a log of the implementation journey that helps the AI (and human developers) learn, adapt, and avoid repeating errors.

7.  **Review & Update Rules (Post-Implementation):**
    *   Once the implementation for the subtask is functionally complete, review all code changes and the relevant chat history.
    *   Identify any new or modified code patterns, conventions, or best practices established during the implementation.
    *   Create new or update existing rules following internal guidelines (previously linked to `cursor_rules.md` and `self_improve.md`).

8.  **Mark Task Complete:**
    *   After verifying the implementation and updating any necessary rules, mark the subtask as completed: `set_task_status` / `task-master set-status --id=<subtaskId> --status=done`.

9.  **Commit Changes (If using Git):**
    *   Stage the relevant code changes and any updated/new rule files (`git add .`).
    *   Craft a comprehensive Git commit message summarizing the work done for the subtask, including both code implementation and any rule adjustments.
    *   Execute the commit command directly in the terminal (e.g., `git commit -m 'feat(module): Implement feature X for subtask <subtaskId>\n\n- Details about changes...\n- Updated rule Y for pattern Z'`).
    *   Consider if a Changeset is needed according to internal versioning guidelines (previously linked to `changeset.md`). If so, run `npm run changeset`, stage the generated file, and amend the commit or create a new one.

10. **Proceed to Next Subtask:**
    *   Identify the next subtask (e.g., using `next_task` / `task-master next`).

## Code Analysis & Refactoring Techniques

- **Top-Level Function Search**:
    - Useful for understanding module structure or planning refactors.
    - Use grep/ripgrep to find exported functions/constants:
      `rg "export (async function|function|const) \w+"` or similar patterns.
    - Can help compare functions between files during migrations or identify potential naming conflicts.

---
*This workflow provides a general guideline. Adapt it based on your specific project needs and team practices.*
```

========================================================================================================================

## FILE: `../.github/instructions/taskmaster.md`

```markdown
---
description: Comprehensive reference for Taskmaster MCP tools and CLI commands.
applyTo: "**/*"
alwaysApply: true
---

# Taskmaster Tool & Command Reference

This document provides a detailed reference for interacting with Taskmaster, covering both the recommended MCP tools, suitable for integrations like VS Code, and the corresponding `task-master` CLI commands, designed for direct user interaction or fallback.

**Note:** For interacting with Taskmaster programmatically or via integrated tools, using the **MCP tools is strongly recommended** due to better performance, structured data, and error handling. The CLI commands serve as a user-friendly alternative and fallback. 

**Important:** Several MCP tools involve AI processing... The AI-powered tools include `parse_prd`, `analyze_project_complexity`, `update_subtask`, `update_task`, `update`, `expand_all`, `expand_task`, and `add_task`.

**ğŸ·ï¸ Tagged Task Lists System:** Task Master now supports **tagged task lists** for multi-context task management. This allows you to maintain separate, isolated lists of tasks for different features, branches, or experiments. Existing projects are seamlessly migrated to use a default "master" tag. Most commands now support a `--tag <name>` flag to specify which context to operate on. If omitted, commands use the currently active tag.

---

## Initialization & Setup

### 1. Initialize Project (`init`)

*   **MCP Tool:** `initialize_project`
*   **CLI Command:** `task-master init [options]`
*   **Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project.`
*   **Key CLI Options:**
    *   `--name <name>`: `Set the name for your project in Taskmaster's configuration.`
    *   `--description <text>`: `Provide a brief description for your project.`
    *   `--version <version>`: `Set the initial version for your project, e.g., '0.1.0'.`
    *   `-y, --yes`: `Initialize Taskmaster quickly using default settings without interactive prompts.`
*   **Usage:** Run this once at the beginning of a new project.
*   **MCP Variant Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project by running the 'task-master init' command.`
*   **Key MCP Parameters/Options:**
    *   `projectName`: `Set the name for your project.` (CLI: `--name <name>`)
    *   `projectDescription`: `Provide a brief description for your project.` (CLI: `--description <text>`)
    *   `projectVersion`: `Set the initial version for your project, e.g., '0.1.0'.` (CLI: `--version <version>`)
    *   `authorName`: `Author name.` (CLI: `--author <author>`)
    *   `skipInstall`: `Skip installing dependencies. Default is false.` (CLI: `--skip-install`)
    *   `addAliases`: `Add shell aliases tm and taskmaster. Default is false.` (CLI: `--aliases`)
    *   `yes`: `Skip prompts and use defaults/provided arguments. Default is false.` (CLI: `-y, --yes`)
*   **Usage:** Run this once at the beginning of a new project, typically via an integrated tool like VS Code. Operates on the current working directory of the MCP server. 
*   **Important:** Once complete, you *MUST* parse a prd in order to generate tasks. There will be no tasks files until then. The next step after initializing should be to create a PRD using the example PRD in .taskmaster/templates/example_prd.txt. 
*   **Tagging:** Use the `--tag` option to parse the PRD into a specific, non-default tag context. If the tag doesn't exist, it will be created automatically. Example: `task-master parse-prd spec.txt --tag=new-feature`.

### 2. Parse PRD (`parse_prd`)

*   **MCP Tool:** `parse_prd`
*   **CLI Command:** `task-master parse-prd [file] [options]`
*   **Description:** `Parse a Product Requirements Document, PRD, or text file with Taskmaster to automatically generate an initial set of tasks in tasks.json.`
*   **Key Parameters/Options:**
    *   `input`: `Path to your PRD or requirements text file that Taskmaster should parse for tasks.` (CLI: `[file]` positional or `-i, --input <file>`)
    *   `output`: `Specify where Taskmaster should save the generated 'tasks.json' file. Defaults to '.taskmaster/tasks/tasks.json'.` (CLI: `-o, --output <file>`)
    *   `numTasks`: `Approximate number of top-level tasks Taskmaster should aim to generate from the document.` (CLI: `-n, --num-tasks <number>`)
    *   `force`: `Use this to allow Taskmaster to overwrite an existing 'tasks.json' without asking for confirmation.` (CLI: `-f, --force`)
*   **Usage:** Useful for bootstrapping a project from an existing requirements document.
*   **Notes:** Task Master will strictly adhere to any specific requirements mentioned in the PRD, such as libraries, database schemas, frameworks, tech stacks, etc., while filling in any gaps where the PRD isn't fully specified. Tasks are designed to provide the most direct implementation path while avoiding over-engineering.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress. If the user does not have a PRD, suggest discussing their idea and then use the example PRD in `.taskmaster/templates/example_prd.txt` as a template for creating the PRD based on their idea, for use with `parse-prd`.

---

## AI Model Configuration

### 2. Manage Models (`models`)
*   **MCP Tool:** `models`
*   **CLI Command:** `task-master models [options]`
*   **Description:** `View the current AI model configuration or set specific models for different roles (main, research, fallback). Allows setting custom model IDs for Ollama and OpenRouter.`
*   **Key MCP Parameters/Options:**
    *   `setMain <model_id>`: `Set the primary model ID for task generation/updates.` (CLI: `--set-main <model_id>`)
    *   `setResearch <model_id>`: `Set the model ID for research-backed operations.` (CLI: `--set-research <model_id>`)
    *   `setFallback <model_id>`: `Set the model ID to use if the primary fails.` (CLI: `--set-fallback <model_id>`)
    *   `ollama <boolean>`: `Indicates the set model ID is a custom Ollama model.` (CLI: `--ollama`)
    *   `openrouter <boolean>`: `Indicates the set model ID is a custom OpenRouter model.` (CLI: `--openrouter`)
    *   `listAvailableModels <boolean>`: `If true, lists available models not currently assigned to a role.` (CLI: No direct equivalent; CLI lists available automatically)
    *   `projectRoot <string>`: `Optional. Absolute path to the project root directory.` (CLI: Determined automatically)
*   **Key CLI Options:**
    *   `--set-main <model_id>`: `Set the primary model.`
    *   `--set-research <model_id>`: `Set the research model.`
    *   `--set-fallback <model_id>`: `Set the fallback model.`
    *   `--ollama`: `Specify that the provided model ID is for Ollama (use with --set-*).`
    *   `--openrouter`: `Specify that the provided model ID is for OpenRouter (use with --set-*). Validates against OpenRouter API.`
    *   `--bedrock`: `Specify that the provided model ID is for AWS Bedrock (use with --set-*).`
    *   `--setup`: `Run interactive setup to configure models, including custom Ollama/OpenRouter IDs.`
*   **Usage (MCP):** Call without set flags to get current config. Use `setMain`, `setResearch`, or `setFallback` with a valid model ID to update the configuration. Use `listAvailableModels: true` to get a list of unassigned models. To set a custom model, provide the model ID and set `ollama: true` or `openrouter: true`.
*   **Usage (CLI):** Run without flags to view current configuration and available models. Use set flags to update specific roles. Use `--setup` for guided configuration, including custom models. To set a custom model via flags, use `--set-<role>=<model_id>` along with either `--ollama` or `--openrouter`.
*   **Notes:** Configuration is stored in `.taskmaster/config.json` in the project root. This command/tool modifies that file. Use `listAvailableModels` or `task-master models` to see internally supported models. OpenRouter custom models are validated against their live API. Ollama custom models are not validated live.
*   **API note:** API keys for selected AI providers (based on their model) need to exist in the mcp.json file to be accessible in MCP context. The API keys must be present in the local .env file for the CLI to be able to read them.
*   **Model costs:** The costs in supported models are expressed in dollars. An input/output value of 3 is $3.00. A value of 0.8 is $0.80. 
*   **Warning:** DO NOT MANUALLY EDIT THE .taskmaster/config.json FILE. Use the included commands either in the MCP or CLI format as needed. Always prioritize MCP tools when available and use the CLI as a fallback.

---

## Task Listing & Viewing

### 3. Get Tasks (`get_tasks`)

*   **MCP Tool:** `get_tasks`
*   **CLI Command:** `task-master list [options]`
*   **Description:** `List your Taskmaster tasks, optionally filtering by status and showing subtasks.`
*   **Key Parameters/Options:**
    *   `status`: `Show only Taskmaster tasks matching this status (or multiple statuses, comma-separated), e.g., 'pending' or 'done,in-progress'.` (CLI: `-s, --status <status>`)
    *   `withSubtasks`: `Include subtasks indented under their parent tasks in the list.` (CLI: `--with-subtasks`)
    *   `tag`: `Specify which tag context to list tasks from. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Get an overview of the project status, often used at the start of a work session.

### 4. Get Next Task (`next_task`)

*   **MCP Tool:** `next_task`
*   **CLI Command:** `task-master next [options]`
*   **Description:** `Ask Taskmaster to show the next available task you can work on, based on status and completed dependencies.`
*   **Key Parameters/Options:**
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
    *   `tag`: `Specify which tag context to use. Defaults to the current active tag.` (CLI: `--tag <name>`)
*   **Usage:** Identify what to work on next according to the plan.

### 5. Get Task Details (`get_task`)

*   **MCP Tool:** `get_task`
*   **CLI Command:** `task-master show [id] [options]`
*   **Description:** `Display detailed information for one or more specific Taskmaster tasks or subtasks by ID.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID of the Taskmaster task (e.g., '15'), subtask (e.g., '15.2'), or a comma-separated list of IDs ('1,5,10.2') you want to view.` (CLI: `[id]` positional or `-i, --id <id>`)
    *   `tag`: `Specify which tag context to get the task(s) from. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Understand the full details for a specific task. When multiple IDs are provided, a summary table is shown.
*   **CRITICAL INFORMATION** If you need to collect information from multiple tasks, use comma-separated IDs (i.e. 1,2,3) to receive an array of tasks. Do not needlessly get tasks one at a time if you need to get many as that is wasteful.

---

## Task Creation & Modification

### 6. Add Task (`add_task`)

*   **MCP Tool:** `add_task`
*   **CLI Command:** `task-master add-task [options]`
*   **Description:** `Add a new task to Taskmaster by describing it; AI will structure it.`
*   **Key Parameters/Options:**
    *   `prompt`: `Required. Describe the new task you want Taskmaster to create, e.g., "Implement user authentication using JWT".` (CLI: `-p, --prompt <text>`)
    *   `dependencies`: `Specify the IDs of any Taskmaster tasks that must be completed before this new one can start, e.g., '12,14'.` (CLI: `-d, --dependencies <ids>`)
    *   `priority`: `Set the priority for the new task: 'high', 'medium', or 'low'. Default is 'medium'.` (CLI: `--priority <priority>`)
    *   `research`: `Enable Taskmaster to use the research role for potentially more informed task creation.` (CLI: `-r, --research`)
    *   `tag`: `Specify which tag context to add the task to. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Quickly add newly identified tasks during development.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 7. Add Subtask (`add_subtask`)

*   **MCP Tool:** `add_subtask`
*   **CLI Command:** `task-master add-subtask [options]`
*   **Description:** `Add a new subtask to a Taskmaster parent task, or convert an existing task into a subtask.`
*   **Key Parameters/Options:**
    *   `id` / `parent`: `Required. The ID of the Taskmaster task that will be the parent.` (MCP: `id`, CLI: `-p, --parent <id>`)
    *   `taskId`: `Use this if you want to convert an existing top-level Taskmaster task into a subtask of the specified parent.` (CLI: `-i, --task-id <id>`)
    *   `title`: `Required if not using taskId. The title for the new subtask Taskmaster should create.` (CLI: `-t, --title <title>`)
    *   `description`: `A brief description for the new subtask.` (CLI: `-d, --description <text>`)
    *   `details`: `Provide implementation notes or details for the new subtask.` (CLI: `--details <text>`)
    *   `dependencies`: `Specify IDs of other tasks or subtasks, e.g., '15' or '16.1', that must be done before this new subtask.` (CLI: `--dependencies <ids>`)
    *   `status`: `Set the initial status for the new subtask. Default is 'pending'.` (CLI: `-s, --status <status>`)
    *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after adding the subtask.` (CLI: `--skip-generate`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Break down tasks manually or reorganize existing tasks.

### 8. Update Tasks (`update`)

*   **MCP Tool:** `update`
*   **CLI Command:** `task-master update [options]`
*   **Description:** `Update multiple upcoming tasks in Taskmaster based on new context or changes, starting from a specific task ID.`
*   **Key Parameters/Options:**
    *   `from`: `Required. The ID of the first task Taskmaster should update. All tasks with this ID or higher that are not 'done' will be considered.` (CLI: `--from <id>`)
    *   `prompt`: `Required. Explain the change or new context for Taskmaster to apply to the tasks, e.g., "We are now using React Query instead of Redux Toolkit for data fetching".` (CLI: `-p, --prompt <text>`)
    *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Handle significant implementation changes or pivots that affect multiple future tasks. Example CLI: `task-master update --from='18' --prompt='Switching to React Query.\nNeed to refactor data fetching...'`
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 9. Update Task (`update_task`)

*   **MCP Tool:** `update_task`
*   **CLI Command:** `task-master update-task [options]`
*   **Description:** `Modify a specific Taskmaster task by ID, incorporating new information or changes. By default, this replaces the existing task details.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The specific ID of the Taskmaster task, e.g., '15', you want to update.` (CLI: `-i, --id <id>`)
    *   `prompt`: `Required. Explain the specific changes or provide the new information Taskmaster should incorporate into this task.` (CLI: `-p, --prompt <text>`)
    *   `append`: `If true, appends the prompt content to the task's details with a timestamp, rather than replacing them. Behaves like update-subtask.` (CLI: `--append`)
    *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
    *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Refine a specific task based on new understanding. Use `--append` to log progress without creating subtasks.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 10. Update Subtask (`update_subtask`)

*   **MCP Tool:** `update_subtask`
*   **CLI Command:** `task-master update-subtask [options]`
*   **Description:** `Append timestamped notes or details to a specific Taskmaster subtask without overwriting existing content. Intended for iterative implementation logging.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID of the Taskmaster subtask, e.g., '5.2', to update with new information.` (CLI: `-i, --id <id>`)
    *   `prompt`: `Required. The information, findings, or progress notes to append to the subtask's details with a timestamp.` (CLI: `-p, --prompt <text>`)
    *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
    *   `tag`: `Specify which tag context the subtask belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Log implementation progress, findings, and discoveries during subtask development. Each update is timestamped and appended to preserve the implementation journey.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 11. Set Task Status (`set_task_status`)

*   **MCP Tool:** `set_task_status`
*   **CLI Command:** `task-master set-status [options]`
*   **Description:** `Update the status of one or more Taskmaster tasks or subtasks, e.g., 'pending', 'in-progress', 'done'.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID(s) of the Taskmaster task(s) or subtask(s), e.g., '15', '15.2', or '16,17.1', to update.` (CLI: `-i, --id <id>`)
    *   `status`: `Required. The new status to set, e.g., 'done', 'pending', 'in-progress', 'review', 'cancelled'.` (CLI: `-s, --status <status>`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Mark progress as tasks move through the development cycle.

### 12. Remove Task (`remove_task`)

*   **MCP Tool:** `remove_task`
*   **CLI Command:** `task-master remove-task [options]`
*   **Description:** `Permanently remove a task or subtask from the Taskmaster tasks list.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID of the Taskmaster task, e.g., '5', or subtask, e.g., '5.2', to permanently remove.` (CLI: `-i, --id <id>`)
    *   `yes`: `Skip the confirmation prompt and immediately delete the task.` (CLI: `-y, --yes`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Permanently delete tasks or subtasks that are no longer needed in the project.
*   **Notes:** Use with caution as this operation cannot be undone. Consider using 'blocked', 'cancelled', or 'deferred' status instead if you just want to exclude a task from active planning but keep it for reference. The command automatically cleans up dependency references in other tasks.

---

## Task Structure & Breakdown

### 13. Expand Task (`expand_task`)

*   **MCP Tool:** `expand_task`
*   **CLI Command:** `task-master expand [options]`
*   **Description:** `Use Taskmaster's AI to break down a complex task into smaller, manageable subtasks. Appends subtasks by default.`
*   **Key Parameters/Options:**
    *   `id`: `The ID of the specific Taskmaster task you want to break down into subtasks.` (CLI: `-i, --id <id>`)
    *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create. Uses complexity analysis/defaults otherwise.` (CLI: `-n, --num <number>`)
    *   `research`: `Enable Taskmaster to use the research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
    *   `prompt`: `Optional: Provide extra context or specific instructions to Taskmaster for generating the subtasks.` (CLI: `-p, --prompt <text>`)
    *   `force`: `Optional: If true, clear existing subtasks before generating new ones. Default is false (append).` (CLI: `--force`)
    *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Generate a detailed implementation plan for a complex task before starting coding. Automatically uses complexity report recommendations if available and `num` is not specified.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 14. Expand All Tasks (`expand_all`)

*   **MCP Tool:** `expand_all`
*   **CLI Command:** `task-master expand --all [options]` (Note: CLI uses the `expand` command with the `--all` flag)
*   **Description:** `Tell Taskmaster to automatically expand all eligible pending/in-progress tasks based on complexity analysis or defaults. Appends subtasks by default.`
*   **Key Parameters/Options:**
    *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create per task.` (CLI: `-n, --num <number>`)
    *   `research`: `Enable research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
    *   `prompt`: `Optional: Provide extra context for Taskmaster to apply generally during expansion.` (CLI: `-p, --prompt <text>`)
    *   `force`: `Optional: If true, clear existing subtasks before generating new ones for each eligible task. Default is false (append).` (CLI: `--force`)
    *   `tag`: `Specify which tag context to expand. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Useful after initial task generation or complexity analysis to break down multiple tasks at once.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 15. Clear Subtasks (`clear_subtasks`)

*   **MCP Tool:** `clear_subtasks`
*   **CLI Command:** `task-master clear-subtasks [options]`
*   **Description:** `Remove all subtasks from one or more specified Taskmaster parent tasks.`
*   **Key Parameters/Options:**
    *   `id`: `The ID(s) of the Taskmaster parent task(s) whose subtasks you want to remove, e.g., '15' or '16,18'. Required unless using 'all'.` (CLI: `-i, --id <ids>`)
    *   `all`: `Tell Taskmaster to remove subtasks from all parent tasks.` (CLI: `--all`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Used before regenerating subtasks with `expand_task` if the previous breakdown needs replacement.

### 16. Remove Subtask (`remove_subtask`)

*   **MCP Tool:** `remove_subtask`
*   **CLI Command:** `task-master remove-subtask [options]`
*   **Description:** `Remove a subtask from its Taskmaster parent, optionally converting it into a standalone task.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID(s) of the Taskmaster subtask(s) to remove, e.g., '15.2' or '16.1,16.3'.` (CLI: `-i, --id <id>`)
    *   `convert`: `If used, Taskmaster will turn the subtask into a regular top-level task instead of deleting it.` (CLI: `-c, --convert`)
    *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after removing the subtask.` (CLI: `--skip-generate`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Delete unnecessary subtasks or promote a subtask to a top-level task.

### 17. Move Task (`move_task`)

*   **MCP Tool:** `move_task`
*   **CLI Command:** `task-master move [options]`
*   **Description:** `Move a task or subtask to a new position within the task hierarchy.`
*   **Key Parameters/Options:**
    *   `from`: `Required. ID of the task/subtask to move (e.g., "5" or "5.2"). Can be comma-separated for multiple tasks.` (CLI: `--from <id>`)
    *   `to`: `Required. ID of the destination (e.g., "7" or "7.3"). Must match the number of source IDs if comma-separated.` (CLI: `--to <id>`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Reorganize tasks by moving them within the hierarchy. Supports various scenarios like:
    *   Moving a task to become a subtask
    *   Moving a subtask to become a standalone task
    *   Moving a subtask to a different parent
    *   Reordering subtasks within the same parent
    *   Moving a task to a new, non-existent ID (automatically creates placeholders)
    *   Moving multiple tasks at once with comma-separated IDs
*   **Validation Features:**
    *   Allows moving tasks to non-existent destination IDs (creates placeholder tasks)
    *   Prevents moving to existing task IDs that already have content (to avoid overwriting)
    *   Validates that source tasks exist before attempting to move them
    *   Maintains proper parent-child relationships
*   **Example CLI:** `task-master move --from=5.2 --to=7.3` to move subtask 5.2 to become subtask 7.3.
*   **Example Multi-Move:** `task-master move --from=10,11,12 --to=16,17,18` to move multiple tasks to new positions.
*   **Common Use:** Resolving merge conflicts in tasks.json when multiple team members create tasks on different branches.

---

## Dependency Management

### 18. Add Dependency (`add_dependency`)

*   **MCP Tool:** `add_dependency`
*   **CLI Command:** `task-master add-dependency [options]`
*   **Description:** `Define a dependency in Taskmaster, making one task a prerequisite for another.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID of the Taskmaster task that will depend on another.` (CLI: `-i, --id <id>`)
    *   `dependsOn`: `Required. The ID of the Taskmaster task that must be completed first, the prerequisite.` (CLI: `-d, --depends-on <id>`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <path>`)
*   **Usage:** Establish the correct order of execution between tasks.

### 19. Remove Dependency (`remove_dependency`)

*   **MCP Tool:** `remove_dependency`
*   **CLI Command:** `task-master remove-dependency [options]`
*   **Description:** `Remove a dependency relationship between two Taskmaster tasks.`
*   **Key Parameters/Options:**
    *   `id`: `Required. The ID of the Taskmaster task you want to remove a prerequisite from.` (CLI: `-i, --id <id>`)
    *   `dependsOn`: `Required. The ID of the Taskmaster task that should no longer be a prerequisite.` (CLI: `-d, --depends-on <id>`)
    *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Update task relationships when the order of execution changes.

### 20. Validate Dependencies (`validate_dependencies`)

*   **MCP Tool:** `validate_dependencies`
*   **CLI Command:** `task-master validate-dependencies [options]`
*   **Description:** `Check your Taskmaster tasks for dependency issues (like circular references or links to non-existent tasks) without making changes.`
*   **Key Parameters/Options:**
    *   `tag`: `Specify which tag context to validate. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Audit the integrity of your task dependencies.

### 21. Fix Dependencies (`fix_dependencies`)

*   **MCP Tool:** `fix_dependencies`
*   **CLI Command:** `task-master fix-dependencies [options]`
*   **Description:** `Automatically fix dependency issues (like circular references or links to non-existent tasks) in your Taskmaster tasks.`
*   **Key Parameters/Options:**
    *   `tag`: `Specify which tag context to fix dependencies in. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Clean up dependency errors automatically.

---

## Analysis & Reporting

### 22. Analyze Project Complexity (`analyze_project_complexity`)

*   **MCP Tool:** `analyze_project_complexity`
*   **CLI Command:** `task-master analyze-complexity [options]`
*   **Description:** `Have Taskmaster analyze your tasks to determine their complexity and suggest which ones need to be broken down further.`
*   **Key Parameters/Options:**
    *   `output`: `Where to save the complexity analysis report. Default is '.taskmaster/reports/task-complexity-report.json' (or '..._tagname.json' if a tag is used).` (CLI: `-o, --output <file>`)
    *   `threshold`: `The minimum complexity score (1-10) that should trigger a recommendation to expand a task.` (CLI: `-t, --threshold <number>`)
    *   `research`: `Enable research role for more accurate complexity analysis. Requires appropriate API key.` (CLI: `-r, --research`)
    *   `tag`: `Specify which tag context to analyze. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Used before breaking down tasks to identify which ones need the most attention.
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.

### 23. View Complexity Report (`complexity_report`)

*   **MCP Tool:** `complexity_report`
*   **CLI Command:** `task-master complexity-report [options]`
*   **Description:** `Display the task complexity analysis report in a readable format.`
*   **Key Parameters/Options:**
    *   `tag`: `Specify which tag context to show the report for. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to the complexity report (default: '.taskmaster/reports/task-complexity-report.json').` (CLI: `-f, --file <file>`)
*   **Usage:** Review and understand the complexity analysis results after running analyze-complexity.

---

## File Management

### 24. Generate Task Files (`generate`)

*   **MCP Tool:** `generate`
*   **CLI Command:** `task-master generate [options]`
*   **Description:** `Create or update individual Markdown files for each task based on your tasks.json.`
*   **Key Parameters/Options:**
    *   `output`: `The directory where Taskmaster should save the task files (default: in a 'tasks' directory).` (CLI: `-o, --output <directory>`)
    *   `tag`: `Specify which tag context to generate files for. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
*   **Usage:** Run this after making changes to tasks.json to keep individual task files up to date. This command is now manual and no longer runs automatically.

---

## AI-Powered Research

### 25. Research (`research`)

*   **MCP Tool:** `research`
*   **CLI Command:** `task-master research [options]`
*   **Description:** `Perform AI-powered research queries with project context to get fresh, up-to-date information beyond the AI's knowledge cutoff.`
*   **Key Parameters/Options:**
    *   `query`: `Required. Research query/prompt (e.g., "What are the latest best practices for React Query v5?").` (CLI: `[query]` positional or `-q, --query <text>`)
    *   `taskIds`: `Comma-separated list of task/subtask IDs from the current tag context (e.g., "15,16.2,17").` (CLI: `-i, --id <ids>`)
    *   `filePaths`: `Comma-separated list of file paths for context (e.g., "src/api.js,docs/readme.md").` (CLI: `-f, --files <paths>`)
    *   `customContext`: `Additional custom context text to include in the research.` (CLI: `-c, --context <text>`)
    *   `includeProjectTree`: `Include project file tree structure in context (default: false).` (CLI: `--tree`)
    *   `detailLevel`: `Detail level for the research response: 'low', 'medium', 'high' (default: medium).` (CLI: `--detail <level>`)
    *   `saveTo`: `Task or subtask ID (e.g., "15", "15.2") to automatically save the research conversation to.` (CLI: `--save-to <id>`)
    *   `saveFile`: `If true, saves the research conversation to a markdown file in '.taskmaster/docs/research/'.` (CLI: `--save-file`)
    *   `noFollowup`: `Disables the interactive follow-up question menu in the CLI.` (CLI: `--no-followup`)
    *   `tag`: `Specify which tag context to use for task-based context gathering. Defaults to the current active tag.` (CLI: `--tag <name>`)
    *   `projectRoot`: `The directory of the project. Must be an absolute path.` (CLI: Determined automatically)
*   **Usage:** **This is a POWERFUL tool that agents should use FREQUENTLY** to:
    *   Get fresh information beyond knowledge cutoff dates
    *   Research latest best practices, library updates, security patches
    *   Find implementation examples for specific technologies
    *   Validate approaches against current industry standards
    *   Get contextual advice based on project files and tasks
*   **When to Consider Using Research:**
    *   **Before implementing any task** - Research current best practices
    *   **When encountering new technologies** - Get up-to-date implementation guidance (libraries, apis, etc)
    *   **For security-related tasks** - Find latest security recommendations
    *   **When updating dependencies** - Research breaking changes and migration guides
    *   **For performance optimization** - Get current performance best practices
    *   **When debugging complex issues** - Research known solutions and workarounds
*   **Research + Action Pattern:**
    *   Use `research` to gather fresh information
    *   Use `update_subtask` to commit findings with timestamps
    *   Use `update_task` to incorporate research into task details
    *   Use `add_task` with research flag for informed task creation
*   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. The research provides FRESH data beyond the AI's training cutoff, making it invaluable for current best practices and recent developments.

---

## Tag Management

This new suite of commands allows you to manage different task contexts (tags).

### 26. List Tags (`tags`)

*   **MCP Tool:** `list_tags`
*   **CLI Command:** `task-master tags [options]`
*   **Description:** `List all available tags with task counts, completion status, and other metadata.`
*   **Key Parameters/Options:**
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
    *   `--show-metadata`: `Include detailed metadata in the output (e.g., creation date, description).` (CLI: `--show-metadata`)

### 27. Add Tag (`add_tag`)

*   **MCP Tool:** `add_tag`
*   **CLI Command:** `task-master add-tag <tagName> [options]`
*   **Description:** `Create a new, empty tag context, or copy tasks from another tag.`
*   **Key Parameters/Options:**
    *   `tagName`: `Name of the new tag to create (alphanumeric, hyphens, underscores).` (CLI: `<tagName>` positional)
    *   `--from-branch`: `Creates a tag with a name derived from the current git branch, ignoring the <tagName> argument.` (CLI: `--from-branch`)
    *   `--copy-from-current`: `Copy tasks from the currently active tag to the new tag.` (CLI: `--copy-from-current`)
    *   `--copy-from <tag>`: `Copy tasks from a specific source tag to the new tag.` (CLI: `--copy-from <tag>`)
    *   `--description <text>`: `Provide an optional description for the new tag.` (CLI: `-d, --description <text>`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)

### 28. Delete Tag (`delete_tag`)

*   **MCP Tool:** `delete_tag`
*   **CLI Command:** `task-master delete-tag <tagName> [options]`
*   **Description:** `Permanently delete a tag and all of its associated tasks.`
*   **Key Parameters/Options:**
    *   `tagName`: `Name of the tag to delete.` (CLI: `<tagName>` positional)
    *   `--yes`: `Skip the confirmation prompt.` (CLI: `-y, --yes`)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)

### 29. Use Tag (`use_tag`)

*   **MCP Tool:** `use_tag`
*   **CLI Command:** `task-master use-tag <tagName>`
*   **Description:** `Switch your active task context to a different tag.`
*   **Key Parameters/Options:**
    *   `tagName`: `Name of the tag to switch to.` (CLI: `<tagName>` positional)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)

### 30. Rename Tag (`rename_tag`)

*   **MCP Tool:** `rename_tag`
*   **CLI Command:** `task-master rename-tag <oldName> <newName>`
*   **Description:** `Rename an existing tag.`
*   **Key Parameters/Options:**
    *   `oldName`: `The current name of the tag.` (CLI: `<oldName>` positional)
    *   `newName`: `The new name for the tag.` (CLI: `<newName>` positional)
    *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)

### 31. Copy Tag (`copy_tag`)

*   **MCP Tool:** `copy_tag`
*   **CLI Command:** `task-master copy-tag <sourceName> <targetName> [options]`
*   **Description:** `Copy an entire tag context, including all its tasks and metadata, to a new tag.`
*   **Key Parameters/Options:**
    *   `sourceName`: `Name of the tag to copy from.` (CLI: `<sourceName>` positional)
    *   `targetName`: `Name of the new tag to create.` (CLI: `<targetName>` positional)
    *   `--description <text>`: `Optional description for the new tag.` (CLI: `-d, --description <text>`)

---

## Miscellaneous

### 32. Sync Readme (`sync-readme`) -- experimental

*   **MCP Tool:** N/A
*   **CLI Command:** `task-master sync-readme [options]`
*   **Description:** `Exports your task list to your project's README.md file, useful for showcasing progress.`
*   **Key Parameters/Options:**
    *   `status`: `Filter tasks by status (e.g., 'pending', 'done').` (CLI: `-s, --status <status>`)
    *   `withSubtasks`: `Include subtasks in the export.` (CLI: `--with-subtasks`)
    *   `tag`: `Specify which tag context to export from. Defaults to the current active tag.` (CLI: `--tag <name>`)

---

## Environment Variables Configuration (Updated)

Taskmaster primarily uses the **`.taskmaster/config.json`** file (in project root) for configuration (models, parameters, logging level, etc.), managed via `task-master models --setup`.

Environment variables are used **only** for sensitive API keys related to AI providers and specific overrides like the Ollama base URL:

*   **API Keys (Required for corresponding provider):**
    *   `ANTHROPIC_API_KEY`
    *   `PERPLEXITY_API_KEY`
    *   `OPENAI_API_KEY`
    *   `GOOGLE_API_KEY`
    *   `MISTRAL_API_KEY`
    *   `AZURE_OPENAI_API_KEY` (Requires `AZURE_OPENAI_ENDPOINT` too)
    *   `OPENROUTER_API_KEY`
    *   `XAI_API_KEY`
    *   `OLLAMA_API_KEY` (Requires `OLLAMA_BASE_URL` too)
*   **Endpoints (Optional/Provider Specific inside .taskmaster/config.json):**
    *   `AZURE_OPENAI_ENDPOINT`
    *   `OLLAMA_BASE_URL` (Default: `http://localhost:11434/api`)

**Set API keys** in your **`.env`** file in the project root (for CLI use) or within the `env` section of your **`.vscode/mcp.json`** file (for MCP/VS Code integration). All other settings (model choice, max tokens, temperature, log level, custom endpoints) are managed in `.taskmaster/config.json` via `task-master models` command or `models` MCP tool.

---

For details on how these commands fit into the development process, see the [dev_workflow.md](.github/instructions/dev_workflow.md).
```

========================================================================================================================

## FILE: `../.taskmaster/config.json`

```markdown
{
  "models": {
    "main": {
      "provider": "openrouter",
      "modelId": "deepseek/deepseek-chat-v3-0324:free",
      "maxTokens": 163840,
      "temperature": 0.2
    },
    "research": {
      "provider": "gemini-cli",
      "modelId": "gemini-2.5-pro",
      "maxTokens": 65536,
      "temperature": 0.1
    },
    "fallback": {
      "provider": "gemini-cli",
      "modelId": "gemini-2.5-pro",
      "maxTokens": 65536,
      "temperature": 0.2
    }
  },
  "global": {
    "logLevel": "info",
    "debug": false,
    "defaultNumTasks": 10,
    "defaultSubtasks": 5,
    "defaultPriority": "medium",
    "projectName": "Taskmaster",
    "ollamaBaseURL": "http://localhost:11434/api",
    "bedrockBaseURL": "https://bedrock.us-east-1.amazonaws.com",
    "responseLanguage": "English",
    "defaultTag": "master",
    "azureOpenaiBaseURL": "https://your-endpoint.openai.azure.com/"
  },
  "claudeCode": {}
}
```

========================================================================================================================

## FILE: `../.taskmaster/state.json`

```markdown
{
  "currentTag": "master",
  "lastSwitched": "2025-07-22T13:23:42.469Z",
  "branchTagMapping": {},
  "migrationNoticeShown": false
}
```

========================================================================================================================

## FILE: `../.taskmaster/templates/example_prd.txt`

```markdown
<context>
# Overview  
[Provide a high-level overview of your product here. Explain what problem it solves, who it's for, and why it's valuable.]

# Core Features  
[List and describe the main features of your product. For each feature, include:
- What it does
- Why it's important
- How it works at a high level]

# User Experience  
[Describe the user journey and experience. Include:
- User personas
- Key user flows
- UI/UX considerations]
</context>
<PRD>
# Technical Architecture  
[Outline the technical implementation details:
- System components
- Data models
- APIs and integrations
- Infrastructure requirements]

# Development Roadmap  
[Break down the development process into phases:
- MVP requirements
- Future enhancements
- Do not think about timelines whatsoever -- all that matters is scope and detailing exactly what needs to be build in each phase so it can later be cut up into tasks]

# Logical Dependency Chain
[Define the logical order of development:
- Which features need to be built first (foundation)
- Getting as quickly as possible to something usable/visible front end that works
- Properly pacing and scoping each feature so it is atomic but can also be built upon and improved as development approaches]

# Risks and Mitigations  
[Identify potential risks and how they'll be addressed:
- Technical challenges
- Figuring out the MVP that we can build upon
- Resource constraints]

# Appendix  
[Include any additional information:
- Research findings
- Technical specifications]
</PRD>
```